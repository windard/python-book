{"./":{"url":"./","title":"介绍","keywords":"","body":"介绍 Python 无所不能 python的强大之处有很大的一方面在于它有各种各样非常强大的库，这里是一些常用的依赖库的使用记录。 有一本书叫《Python 标准库》,几百个标准库,还有一本书叫Python图像处理的标准库。 《Python 标准库》 | 《PythonImagingLibrary中文手册》 其实看 python 的官方文档和一本 python cookbook ，就已经很足够了。 Python 标准库 | Python Cookbook 3rd Edition Documentation 以下是我在Python学习中学到的函数库，也不敢说作为教程，只能算是自己记录下来作为参考。 好记性不如烂笔头。 &#x1F40D;&#x1F601;&#x1F604;&#x1F440;&#x1F44C;&#x1F409;&#x1F929;&#x1F44C;&#x1F61D; 离线阅读: 下载 pdf 下载 mobi 下载 epub Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-28 13:02:52 "},"official/":{"url":"official/","title":"官方库","keywords":"","body":"官方库 这里是一些 python 的官方库，无需安装，python 自带。 所以其实也不能叫官方库，应该叫内置库 Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-24 10:10:53 "},"official/os.html":{"url":"official/os.html","title":"os","keywords":"","body":"os 非常基础的一个库，但是却实现了我一个想了很久了功能，识别目录下的所有文件。 取得当前目录-- os.getcwd 更改当前目录-- os.chdir 创建一个目录-- os.mkdir 创建多级目录-- os.makedirs 删除一个目录,只能删除空目录-- os.rmdir 删除多个目录,删除目录及其下内容-- os.removedirs 获取目录中的文件及子目录的列表-- os.listdir 隐藏文件也会显示出来 删除一个文件-- os.remove 删除一个文件-- os.unlink 文件或者文件夹重命名-- os.rename(old， new) 获取文件大小-- os.path.getsize 获取文件属性-- os.stat 修改文件权限与时间戳-- os.chmod 路径中加入新的内容-- os.path.join(path,file) 将路径分解为目录名和文件名-- os.path.split 将目录分解为目录加文件名和文件名的扩展名-- os.path.splitext 获得路径的路径名-- os.path.dirname 获得路径的文件名-- os.path.basename 判断一个路径是否存在或是否为路径-- os.path.isdir 判断一个文件是否存在或这否为文件-- os.path.isfile 判断一个路径（目录或文件）是否存在——os.path.exists 判断一个路径是否是绝对路径-- os.path.isabs 获得一个绝对路径 -- os.path.abspath 或者 os.path.realpath 获得当前文件所在的文件夹 os.path.abspath(os.path.dirname(__file__)) 或者 os.path.dirname(os.path.abspath(__file__)) 或者 os.path.abspath(os.curdir) 获得一个相对路径 -- os.path.relpath(path, start) 读取和设置环境变量-- os.getenv 与 os.putenv 获取家目录-- os.path.expanduser('~') 指示你正在使用的平台-- os.name 对于Windows，它是nt，而对于Linux/Unix/Mac用户，它是posix 给出当前平台使用的路径分隔符 -- os.sep Windows 使用 \\ Linux 使用 /，Mac OS 使用 / 给出当前平台使用的行终止符-- os.linesep Windows 使用 \\r\\n,Linux 使用 \\n,低版本 Mac OS 使用 \\r，高版本 Mac 用 \\n 给出当前平台使用的分割路径的分隔符 -- os.pathsep Windows 使用 ; ，Linux 使用 : Mac OS 使用 : 运行shell命令-- os.system 但是这个执行命令行没有返回值，直接输出，不管你有没有print 执行shell命令-- os.popen 执行命令行，返回一个file open的对象，需要read才能得到执行结果，但是还是没有返回值，如果需要更多的命令行操作，可以使用commands库 执行 shell 命令 -- os.execlp 如 os.execlp('ls','') 并替换当前进程 终止当前进程-- os._exit 比如 os._exit(0) 还能从子线程中终止主线程。sys.exit 则不能这样 循环遍历目录-- os.walk 返回一个三元组，第一个是路径，第二个是路径下的目录，第三个是路径下的非目录。 系统环境变量-- os.environ 返回系统环境变量，或者是在 HTTP 请求中的请求头。 生成随机字符串-- os.urandom 比如 os.urandom(num) 返回 num 个随机字符串，在 ASCII 中，不一定是可打印字符。 检查文件系统权限-- os.access(filename, privilege) 创建一个新的进程 -- os.fork 只在 linux 和 unix 上使用，windows 用不了 获得当前进程的 pid -- os.getpid 获得父进程的 pid -- os.getppid 杀死一个进程 -- os.kill 比如 os.kill(os.getpid(), 9) 杀死当前进程 # coding=utf-8 import os currentpath = os.getcwd() print currentpath changedpath = 'C:\\\\Users\\\\dell\\\\Desktop' os.chdir(changedpath) currentpath = os.getcwd() print currentpath os.mkdir('hello') changedpath = changedpath + '\\\\hello' print changedpath os.chdir(changedpath) currentpath = os.getcwd() print currentpath os.makedirs('hello\\\\hello') changedpath = changedpath + '\\\\hello\\\\hello' print changedpath os.chdir(changedpath) currentpath = os.getcwd() print currentpath os.chdir('../') currentpath = os.getcwd() print currentpath currentlist = os.listdir(currentpath) print currentlist os.rmdir('hello') currentlist = os.listdir(currentpath) print currentlist os.chdir('../../') currentpath = os.getcwd() currentlist = os.listdir(currentpath) print currentlist os.removedirs('hello\\\\hello') currentlist = os.listdir(currentpath) print currentlist FILE1 = open('test1.txt','w') FILE1.close() FILE2 = open('test2.txt','w') FILE2.close() currentlist = os.listdir(currentpath) print currentlist os.remove('test1.txt') currentlist = os.listdir(currentpath) print currentlist os.rename('test2.txt','newtest.txt') currentlist = os.listdir(currentpath) print currentlist FILE = open('newtest.txt','w') FILE.write('THis is for test') FILE.close() FILESIZE = os.path.getsize('newtest.txt') print FILESIZE FILESTAT = os.stat('newtest.txt') print FILESTAT currentpath = currentpath + \"\\\\newtest.txt\" print currentpath (splitpath,splitfile) = os.path.split(currentpath) print splitpath print splitfile (splitpath,splitfile) = os.path.splitext(currentpath) print splitpath print splitfile splitpath = os.path.dirname(currentpath) splitfile = os.path.basename(currentpath) print splitpath print splitfile isdir = os.path.isfile(currentpath) isfile = os.path.isdir(currentpath) print isdir print isfile os.remove('newtest.txt') currentpath = os.path.dirname(currentpath) isdir = os.path.isfile(currentpath) isfile = os.path.isdir(currentpath) print isdir print isfile isexist = os.path.exists(currentpath) print isexist isabs = os.path.isabs(currentpath) print isabs osname = os.name print osname linesep = os.linesep print linesep os.system('dir') 保存为 os_demo.py，运行，看一下结果 测试一下系统权限 # coding=utf-8 import os print \"File Name: \",__file__ print \"Exist File ? \",os.access(__file__,os.F_OK) print \"Read File ? \",os.access(__file__,os.R_OK) print \"Write File ? \",os.access(__file__,os.W_OK) print \"Execute File ? \",os.access(__file__,os.X_OK) 结果是 File Name: /home/windard/github/Python_Lib/code/os_access.py Exist File ? True Read File ? True Write File ? True Execute File ? False 试一下关于进程，ubuntu 下 # coding=utf-8 import os # pid = os.fork() # if pid: # print \"Child Pid : %s, Current Pid %s\"%(pid,os.getpid()) # else: # print \"I am the child,Current Pid %s\"%(os.getpid()) def create_child(): pid0=os.getpid() print '主进程',pid0 try: pid1=os.fork() except OSError: print u'你的系统不支持fork' exit() if pid1 结果是 主进程 29511 这是在主进程里，可以看到子进程的 pid:29512 ，和自己的进程:29511 ,父进程也是其他的进程: 9372 这句话,父进程和子进程都会执行 这是在子进程里，看不到子进程的 pid:0，因为那就是自己的 pid: 29512，父进程就是主进程: 29511 这句话,父进程和子进程都会执行 重点是还可以运行shell命令。 import os shell = \"dir\" print os.system(shell) 保存为os_shell.py，运行，看一下结果。 试一下用os.walk()来遍历文件。 import os dirlist = r\"C:\\Users\\dell\\Desktop\\2048\" filenum = 0 dirnum = 0 for i,j,k in os.walk(dirlist): print i for i,j,k in os.walk(dirlist): for item in k: print item filenum = filenum + 1 for index in range(len(k)): dirnum = dirnum + 1 print filenum print dirnum 保存为os_walk.py，运行，看一下结果。 给一个查看目录下的所有文件的代码，如果有目录则空格表示递进关系 # coding=utf-8 import os def showall(path,leavel=0,filenum=0,show=True): newnum = filenum currentpath = path; dirandfile = os.listdir(path) for item in dirandfile: newpath = os.path.join(currentpath,item) if os.path.isdir(newpath): num = showall(newpath,leavel+1,newnum,show) newnum = num else: newnum = newnum + 1 tab_stop = \"\" if show: for tab in range(leavel): tab_stop = tab_stop + \" \" print tab_stop + newpath return newnum if __name__ == '__main__': num = showall('./',show=False) print \"File Number : \" + str(num) 查看系统环境变量 # coding=utf-8 import os environment = os.environ for i,j in environment.items(): print \"%s : %s \"%(i,j) 我的电脑的环境变量 TMP : C:\\Users\\dell\\AppData\\Local\\Temp COMPUTERNAME : YANGWENQIANG USERDOMAIN : YANGWENQIANG GOROOT : C:\\Go\\ PSMODULEPATH : C:\\Users\\dell\\Documents\\WindowsPowerShell\\Modules;C:\\Program Files\\WindowsPowerShell\\Modules;C:\\WINDOWS\\system32\\WindowsPowerShell\\v1.0\\Modules\\ COMMONPROGRAMFILES : C:\\Program Files (x86)\\Common Files PROCESSOR_IDENTIFIER : Intel64 Family 6 Model 69 Stepping 1, GenuineIntel PROGRAMFILES : C:\\Program Files (x86) PROCESSOR_REVISION : 4501 PATH : C:\\Python27\\Lib\\site-packages\\PyQt4;C:\\ProgramData\\Oracle\\Java\\javapath;C:\\Program Files\\Dell\\DW WLAN Card;C:\\Perl64\\site\\bin;C:\\Perl64\\bin;C:\\Program Files (x86)\\Common Files\\Intel\\Shared Files\\cpp\\bin\\Intel64;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files\\WIDCOMM\\Bluetooth Software\\;C:\\Program Files\\WIDCOMM\\Bluetooth Software\\syswow64;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;D:\\Program Files (x86)\\QuickTime\\QTSystem\\;D:\\Program Files\\TortoiseSVN\\bin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\Python34;C:\\Python27;C:\\Perl64;C:\\Program Files\\Java\\jdk1.8.0_60\\bin;D:\\Program Files (x86)\\Sublime text2\\Sublime2\\Sublime2\\Sublime;C:\\Users\\dell\\AppData\\Local\\Google\\Chrome\\Application;C:\\mingw;C:\\Python27\\Scripts;C:\\Ruby22-x64;C:\\PHP;C:\\curl-7.33.0-win64-ssl-sspi;C:\\curl-7.33.0-win64-ssl-sspi;C:\\Program Files (x86)\\MySQL\\MySQL Server 5.7\\bin;D:\\Program Files (x86)\\MySQL\\MySQL Server 5.7\\bin;C:\\sqlite3;C:\\Apache24\\bin;C:\\gunwin32\\GetGnuWin32\\bin;D:\\Program Files (x86)\\Tesseract-OCR;C:\\Users\\dell\\.ssh\\Python_Lib\\project;C:\\MinGW\\bin;D:\\Program Files\\cmder\\bin;D:\\Program Files\\cmder;C:\\Users\\dell\\.ssh\\Python_Lib\\project;C:\\Go\\bin;C:\\Program Files (x86)\\Google\\Chrome\\Application;D:\\Program Files\\nodejs\\;D:\\Program Files\\VMare\\OVFTool;D:\\Program Files (x86)\\Git\\cmd;D:\\Program Files (x86)\\Git\\bin;C:\\Ruby22-x64\\bin;D:\\Program Files (x86)\\Nmap;C:\\Users\\dell\\AppData\\Roaming\\npm SYSTEMROOT : C:\\WINDOWS PROGRAMFILES(X86) : C:\\Program Files (x86) C_EM64T_REDIST11 : C:\\Program Files (x86)\\Common Files\\Intel\\Shared Files\\cpp\\ ASL.LOG : Destination=file TESSDATA_PREFIX : D:\\Program Files (x86)\\Tesseract-OCR\\ TEMP : C:\\Users\\dell\\AppData\\Local\\Temp WINDIR : C:\\WINDOWS COMMONPROGRAMFILES(X86) : C:\\Program Files (x86)\\Common Files PROCESSOR_ARCHITECTURE : x86 ALLUSERSPROFILE : C:\\ProgramData LOCALAPPDATA : C:\\Users\\dell\\AppData\\Local FPS_BROWSER_USER_PROFILE_STRING : Default HOMEPATH : \\Users\\dell USERDOMAIN_ROAMINGPROFILE : YANGWENQIANG JAVA_HOME : C:\\Program Files\\Java\\jdk1.8.0_60 PROGRAMW6432 : C:\\Program Files USERNAME : dell LOGONSERVER : \\\\MicrosoftAccount COMSPEC : C:\\WINDOWS\\system32\\cmd.exe PROGRAMDATA : C:\\ProgramData CLASSPATH : .;D:\\Program Files (x86)\\QuickTime\\QTSystem\\QTJava.zip;C:\\Program Files\\Java\\jdk1.8.0_60\\bin;C:\\Program Files\\Java\\jdk1.8.0_60\\lib\\tools.jar;C:\\Users\\dell\\Desktop\\python\\java FPS_BROWSER_APP_PROFILE_STRING : Internet Explorer AWE_DIR : D:\\Program Files (x86)\\Khrona LLC\\Awesomium SDK\\1.6.6\\ SESSIONNAME : Console PATHEXT : .COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.RB;.RBW;.CPL CONFIGSETROOT : C:\\WINDOWS\\ConfigSetRoot FP_NO_HOST_CHECK : NO QTJAVA : D:\\Program Files (x86)\\QuickTime\\QTSystem\\QTJava.zip OPENSSL_CONF : C:\\OpenSSL-Win32\\bin\\openssl.cfg MOZ_PLUGIN_PATH : C:\\Program Files (x86)\\Foxit Software\\Foxit Reader Plus\\plugins\\ HOMEDRIVE : C: SYSTEMDRIVE : C: NUMBER_OF_PROCESSORS : 4 APPDATA : C:\\Users\\dell\\AppData\\Roaming PROCESSOR_LEVEL : 6 PROCESSOR_ARCHITEW6432 : AMD64 COMMONPROGRAMW6432 : C:\\Program Files\\Common Files OS : Windows_NT PUBLIC : C:\\Users\\Public USERPROFILE : C:\\Users\\dell 若是作为 cgi 脚本则也会显示 header 的请求头 # coding=utf-8 import os environment = os.environ print \"Content-type:text/html\\r\\n\\r\\n\" for i,j in environment.items(): print \"%s : %s \"%(i,j) ALLUSERSPROFILE:C:\\ProgramData APPDATA:C:\\Users\\dell\\AppData\\Roaming ASL.LOG:Destination=file AWE_DIR:D:\\Program Files (x86)\\Khrona LLC\\Awesomium SDK\\1.6.6\\ C_EM64T_REDIST11:C:\\Program Files (x86)\\Common Files\\Intel\\Shared Files\\cpp\\ CLASSPATH:.;D:\\Program Files (x86)\\QuickTime\\QTSystem\\QTJava.zip;%JAVA_HOME%\\bin;%JAVA_HOME%\\lib\\tools.jar;C:\\Users\\dell\\Desktop\\python\\java COMMONPROGRAMFILES:C:\\Program Files (x86)\\Common Files COMMONPROGRAMFILES(X86):C:\\Program Files (x86)\\Common Files COMMONPROGRAMW6432:C:\\Program Files\\Common Files COMPUTERNAME:YANGWENQIANG COMSPEC:C:\\WINDOWS\\system32\\cmd.exe CONFIGSETROOT:C:\\WINDOWS\\ConfigSetRoot Content-type:text/html CONTENT_LENGTH: CONTENT_TYPE:text/plain Date:Thu, 18 Aug 2016 14:05:03 GMT FP_NO_HOST_CHECK:NO FPS_BROWSER_APP_PROFILE_STRING:Internet Explorer FPS_BROWSER_USER_PROFILE_STRING:Default GATEWAY_INTERFACE:CGI/1.1 GOROOT:C:\\Go\\ HOMEDRIVE:C: HOMEPATH:\\Users\\dell HTTP_ACCEPT:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8 HTTP_COOKIE:_ga=GA1.1.2013049555.1445440760 HTTP_REFERER: HTTP_USER_AGENT:Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36 JAVA_HOME:C:\\Program Files\\Java\\jdk1.8.0_60 LOCALAPPDATA:C:\\Users\\dell\\AppData\\Local LOGONSERVER:\\\\MicrosoftAccount MOZ_PLUGIN_PATH:C:\\Program Files (x86)\\Foxit Software\\Foxit Reader Plus\\plugins\\ NUMBER_OF_PROCESSORS:4 OPENSSL_CONF:C:\\OpenSSL-Win32\\bin\\openssl.cfg OS:Windows_NT PATH:C:\\Python27\\Lib\\site-packages\\PyQt4;C:\\ProgramData\\Oracle\\Java\\javapath;C:\\Program Files\\Dell\\DW WLAN Card;C:\\Perl64\\site\\bin;C:\\Perl64\\bin;C:\\Program Files (x86)\\Common Files\\Intel\\Shared Files\\cpp\\bin\\Intel64;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files\\WIDCOMM\\Bluetooth Software\\;C:\\Program Files\\WIDCOMM\\Bluetooth Software\\syswow64;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;D:\\Program Files (x86)\\QuickTime\\QTSystem\\;D:\\Program Files\\TortoiseSVN\\bin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\Python34;C:\\Python27;C:\\Perl64;C:\\Program Files\\Java\\jdk1.8.0_60\\bin;D:\\Program Files (x86)\\Sublime text2\\Sublime2\\Sublime2\\Sublime;C:\\Users\\dell\\AppData\\Local\\Google\\Chrome\\Application;C:\\mingw;C:\\Python27\\Scripts;C:\\Ruby22-x64;C:\\PHP;C:\\curl-7.33.0-win64-ssl-sspi;C:\\curl-7.33.0-win64-ssl-sspi;C:\\Program Files (x86)\\MySQL\\MySQL Server 5.7\\bin;D:\\Program Files (x86)\\MySQL\\MySQL Server 5.7\\bin;C:\\sqlite3;C:\\Apache24\\bin;C:\\gunwin32\\GetGnuWin32\\bin;D:\\Program Files (x86)\\Tesseract-OCR;C:\\Users\\dell\\.ssh\\Python_Lib\\project;C:\\MinGW\\bin;D:\\Program Files\\cmder\\bin;D:\\Program Files\\cmder;C:\\Users\\dell\\.ssh\\Python_Lib\\project;C:\\Go\\bin;C:\\Program Files (x86)\\Google\\Chrome\\Application;D:\\Program Files\\nodejs\\;D:\\Program Files\\VMare\\OVFTool;D:\\Program Files (x86)\\Git\\cmd;D:\\Program Files (x86)\\Git\\bin;C:\\Ruby22-x64\\bin;D:\\Program Files (x86)\\Nmap;C:\\Users\\dell\\AppData\\Roaming\\npm PATH_INFO: PATH_TRANSLATED:C:\\Users\\dell\\Desktop\\python PATHEXT:.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.RB;.RBW;.CPL PROCESSOR_ARCHITECTURE:x86 PROCESSOR_ARCHITEW6432:AMD64 PROCESSOR_IDENTIFIER:Intel64 Family 6 Model 69 Stepping 1, GenuineIntel PROCESSOR_LEVEL:6 PROCESSOR_REVISION:4501 PROGRAMDATA:C:\\ProgramData PROGRAMFILES:C:\\Program Files (x86) PROGRAMFILES(X86):C:\\Program Files (x86) PROGRAMW6432:C:\\Program Files PSMODULEPATH:C:\\Users\\dell\\Documents\\WindowsPowerShell\\Modules;C:\\Program Files\\WindowsPowerShell\\Modules;C:\\WINDOWS\\system32\\WindowsPowerShell\\v1.0\\Modules\\ PUBLIC:C:\\Users\\Public QTJAVA:D:\\Program Files (x86)\\QuickTime\\QTSystem\\QTJava.zip QUERY_STRING: REMOTE_ADDR:127.0.0.1 REMOTE_HOST:YangWenqiang REQUEST_METHOD:GET SCRIPT_NAME:/cgi-bin/environment.py Server:SimpleHTTP/0.6 Python/2.7.10 SERVER_NAME:YangWenqiang SERVER_PORT:8001 SERVER_PROTOCOL:HTTP/1.0 SERVER_SOFTWARE:SimpleHTTP/0.6 Python/2.7.10 SESSIONNAME:Console SYSTEMDRIVE:C: SYSTEMROOT:C:\\WINDOWS TEMP:C:\\Users\\dell\\AppData\\Local\\Temp TESSDATA_PREFIX:D:\\Program Files (x86)\\Tesseract-OCR\\ TMP:C:\\Users\\dell\\AppData\\Local\\Temp USERDOMAIN:YANGWENQIANG USERDOMAIN_ROAMINGPROFILE:YANGWENQIANG USERNAME:dell USERPROFILE:C:\\Users\\dell WINDIR:C:\\WINDOWS Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-24 10:10:53 "},"official/sys.html":{"url":"official/sys.html","title":"sys","keywords":"","body":"sys 基本使用 进阶操作 这个模块也可以传入命令行参数，但是它的参数必须是指定的，没有argparse那么好用，毕竟，这个库的主要功能不是为了传递命令行参数。 基本使用 sys.argv 获得传入的命令行参数。 # coding=utf-8 import sys #默认第0个是程序自身 print sys.argv[1] #默认传进来的参数都是字符串，所以这样的加法是直接相加 print sys.argv[2] + sys.argv[3] #如果想要做加法的话需要这样相加 print int(sys.argv[2])+int(sys.argv[3]) #计算传进来的未知长度的数字之和 num = 0 for i in sys.argv[2:]: num = num+int(i) print num 保存为 sys_argv.py，运行，看一下结果。 sys.platform() 获得当前终端是Windows下还是Linux下。 sys.exit(n) 退出程序，它有一个可选的整数参数，当n为0是是正常退出，其他为不正常，可抛异常事件捕获，默认为0。 注意，此处的sys.exit()和os._exit()和exit()/quit()都能够退出Python程序但是sys.exit()一般用在主线程中退出整个Python进程，因为在子线程中其无法结束主线程而os._exit()不抛出异常，不执行清理工作，能够退出主线程exit()/quit()一般在交互式shell中使用。 sys.path 系统的环境变量，返回列表，还可以用 python -m site 查看 import sys print sys.platform path = sys.path for i in path: print i sys.exit(0) print \"This won't run\" 保存为 sys_platform.py，运行，看一下结果。 进阶操作 sys.modules() python导入了哪些库，返回元组。 sys.version Python解释器的版本信息。 sys.hexversion 用十六进制表示Python解释器的版本号。 sys.maxint 最大的int值 sys.maxunicode 最大的Unicode值 sys.copyright Python解释器的版权信息 sys.version_info Python解释器的详细信息 sys.api_version 解释器的C的API版本 sys.exec_prefix Python文件的安装路径 sys.byteorder 本地字节规则的指示器，返回big表示big-endian，little表示little-endian sys.getdefaultencoding() 返回你当前所用的默认编码格式。Python z.x返回ASCII，Python 3.x返回Unicode sys.setdefaultencoding() 设定当前的默认编码格式 sys.executable 返回Python解释器的具体位置 sys.getwindowsversion() 获得Windows版本 import sys print sys.version print sys.version_info print sys.hexversion print sys.api_version print sys.exec_prefix print sys.executable print sys.maxint print sys.maxunicode print sys.byteorder print sys.getdefaultencoding() print sys.getwindowsversion() print sys.getfilesystemencoding() modules = sys.modules for i in modules.keys(): print i print sys.copyright 保存为 sys_modules.py，运行，看一下结果。 sys.platform 解释器运行的平台名称 sys.stdout 标准输出流 sys.stdin 标准输入流 sys.stderr 错误输出流 import sys data = sys.stdin print data sys.stdout.write(\"hello,world\") 保存为 sys_std.py，运行，看一下结果。 sys.getrecursionlimit() 获得 python 最大递归深度 sys.setrecursionlimit(15000) 在 Mac 上默认为 1000 Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-24 10:10:53 "},"official/re.html":{"url":"official/re.html","title":"re","keywords":"","body":"re 正则表达式基本语法 简单使用 后向引用 高级使用 贪婪与懒惰 分组与捕获 常用正则 参考链接 python 的正则表达式库，现在几乎所有的编程语言都支持正则表达式了，无可否认，正则表达式确实强大。 正则表达式基本语法 与其他编程语言的正则表达式基本类似。 特殊字符 匹配说明 \\ 转义字符 \\d 单个数字 [0-9] \\D 单个非数字 \\s 单个空白字符[\\t\\n\\r\\f\\v] \\S 单个非空白字符 \\w 单个单词字符[a-zA-Z0-9] \\W 单个非单词字符[^\\w] \\A 匹配字符串的开头 \\Z 匹配字符串的结尾 \\b 匹配仅在开头或结尾的空字符 \\B 匹配不在开头或结尾的空字符 \\\\ 匹配字符\\ . 匹配除换行符\\n之外的任意字符 * 匹配前一个字符零次到无限次 + 匹配前一个字符一次到无限次 ？ 匹配前一个字符零次或一次 {m} 匹配前一个字符m次 {m,n} 匹配前一个字符m次到n次 ^ 匹配字符串的开头，也可以在一个字符集内表示取非 $ 匹配字符串的结尾 [……] 表示一个字符集 (……) 表示一个分组 简单使用 python提供了两种不同的基本正则匹配，分别是match和search。 match是从字符串开头做匹配，search是从字符串中做任意匹配，返回值都是一个Match实例,他们的用法基本一致， match(pattern, string, flags=0) search(pattern, string, flags=0)。 在python里面为了避免反斜杠\\的困扰，一般都使用原生字符串，即使用r'XXX' >>> a = re.match(r\"he\",\"hello , world\") >>> a >>> a.group() 'he' >>> b = re.search(r\"wo\",\"hello , world\") >>> b >>> b.group() 'wo' >>> c = re.match(r\"wo\",\"hello , world\") >>> c >>> type(c) >>> re.match(r'(hello) , (world)', a).group(0) 'hello , world' 但是这种匹配一般只能找到匹配的一个，有时我们需要找到所有的匹配，这就需要findall函数，用法也与上面的两个一样, 直接返回一个数组，数组的每一项都是字符串。 findall(pattern, string, flags=0) >>> d = re.findall(r\"wo\",\"hello , world\") >>> d ['wo'] >>> e = re.findall(r\"\\w\",\"hello , world\") >>> e ['h', 'e', 'l', 'l', 'o', 'w', 'o', 'r', 'l', 'd'] >>> re.findall(r\"\\d+\", \"2333abc3uio890da123\") ['2333', '3', '890', '123'] 除了查找之外，正则表达式还有两个很重要的功能就是分割与替换，在这里分别是sub和split，都是返回改变之后的字符串，传入值保持不变。 sub(pattern, repl, string, count=0, flags=0) split(pattern, string, maxsplit=0, flags=0) repl 即可以为一个字符串，也可以为一个可执行函数 >>> a = \"hello , world\" >>> b = re.sub(r\"o\",\"0\",\"hello , world\") >>> b 'hell0 , w0rld' >>> a 'hello , world' >>> c = re.split(r\"\\s\",\"hello , world\") >>> c ['hello', ',', 'world'] >>> a 'hello , world' >>> re.sub(r'(hello) , (world)', r'\\2 , \\1', a) 'world , hello' >>> '%s , %s' % re.match(r'(hello) , (world)', a).groups() 'hello , world' >>> '%s , %s' % (re.match(r'(hello) , (world)', a).group(2), re.match(r'(hello) , (world)', a).group(1)) 'world , hello' >>> re.search(r\"(.+?)\\1+\", 'dxabcabcyyyydxycxcxz').group() 'abcabc' 关于sub函数，还有一个subn函数，用法与sub一致，但是返回一个元组，由改变之后的字符串和改变的个数组成 >>> b = re.subn(r\"o\",\"0\",\"hello , world\") >>> b ('hell0 , w0rld', 2) >>> a 'hello , world' 后向引用 同时，也可以用在搜索查找的时候。 在找到连续的重复字符, \\1 可以用来指代已经匹配到的第一个分组 需注意，引用分组的匹配值必须与第一个分组匹配值相等才能匹配到，如果只是规则相同但是匹配值不同是匹配不到的 In [4]: re.search(r\"(.+?)\\1+\", 'dxabcabcyyyydxycxcxz').group() Out[4]: 'abcabc' In [5]: re.search(r\"(.+?)\\1+\", 'dxabcabcyyyydxycxcxz').groups() Out[5]: ('abc',) 在 sublime 中做替换时，可以使用 $1 表示匹配到的第一个分组，使用 $2 表示匹配到的第二个分组，这样可以用来做数据替换和提取。 在 python 中同理，使用 \\1 表示匹配到的第一个分组，使用 \\2 表示匹配到的第二个分组，使用 \\0 表示被匹配到的字符串本身。 使用 match 从头开始匹配，使用 search 从中匹配 使用 group 查看全部匹配结果，使用 groups 查看匹配分组结果, 使用 groupdict 根据分组命名查看匹配结果。 查找 abb 型数据 >>> re.compile(r'(a)(b)\\2*').search('abbbb').groups() ('a', 'b') >>> re.compile(r'(a)(b)\\2*').search('abbbb').group() 'abbbb' 高级使用 高级使用是先将正则表达式的字符串形式编译成Pattern实例，然后用Pattern实例处理字符串并得到一个Match实例，再对这个Match实例进行处理。 # coding=utf-8 import re pattern = re.compile(r\"he\") match = pattern.match(\"hello , world\") if match: print match.group() 保存为re_demo.py，执行，看一下结果。 compile函数compile(pattern, flags=0)，这里的参数flags和上面的函数里的flags都是匹配模式，可以使用|表示同时生效，可选的参数有： re.I(re.IGNORECASE): 忽略大小写 re.M(re.MULTILINE): 多行模式，改变'^'和'$'的行为 re.S(re.DOTALL): 点任意匹配模式，改变'.'的行为 re.L(re.LOCALE): 使预定字符类\\w \\W \\b \\B \\s \\S取决于当前区域设定 re.U(re.UNICODE): 使预定字符类\\w \\W \\b \\B \\s \\S \\d \\D取决于unicode定义的字符属性 re.X(re.VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释 Match对象 是一次匹配的结果，包含很多关于此次匹配的信息 属性： string: 匹配时传入的文本 re: 匹配时使用的Pattern对象 pos: 文本中正则表达式开始搜索的索引。 endpos: 文本中正则表达式结束搜索的索引。 lastindex: 最后一个被捕获的分组在文本中的索引。如果没有被捕获的分组，将为None lastgroup: 最后一个被捕获的分组的别名。如果这个分组没有别名或者没有被捕获的分组，将为None 方法： group([group1, …]): 获得一个或多个分组截获的字符串；指定多个参数时将以元组形式返回。group1可以使用编号也可以使用别名；编号0代表整个匹配的子串；不填写参数时，返回group(0),相当于全部返回；没有截获字符串的组返回None；截获了多次的组返回最后一次截获的子串 groups([default]): 以元组形式返回全部分组截获的字符串。相当于调用group(1,2,…last)。default表示没有截获字符串的组以这个值替代，默认为None groupdict([default]): 返回以有别名的组的别名为键、以该组截获的子串为值的字典，没有别名的组不包含在内。default含义同上 start([group]): 返回指定的组截获的子串在string中的起始索引（子串第一个字符的索引）。group默认值为0 end([group]): 返回指定的组截获的子串在string中的结束索引（子串最后一个字符的索引+1）。group默认值为0 span([group]): 返回(start(group), end(group)) expand(template): 将匹配到的分组代入template中然后返回。template中可以使用\\id或\\g、\\g引用分组，但不能使用编号0。\\id与\\g是等价的；但\\10将被认为是第10个分组，如果你想表达\\1之后是字符'0'，只能使用\\g0 # coding=utf-8 import re pattern = re.compile(r\"(\\w{1,6})(\\s)(\\,)(\\s)(\\w*)$\") m = re.match(pattern,\"hello , world\") print \"m.string:\", m.string print \"m.re:\", m.re print \"m.re.pattern:\", m.re.pattern print \"m.pos:\", m.pos print \"m.endpos:\", m.endpos print \"m.lastindex:\", m.lastindex print \"m.lastgroup:\", m.lastgroup print \"m.group():\", m.group() print \"m.group(1,2):\", m.group(1, 2) print \"m.groups():\", m.groups() print \"m.groupdict():\", m.groupdict() print \"m.start(2):\", m.start(2) print \"m.end(2):\", m.end(2) print \"m.span(2):\", m.span(2) 保存为re_complex.py，运行，看一下结果。 贪婪与懒惰 正则表达式默认是贪婪模式，即匹配尽可能多的字符，如 + 匹配一个到无穷多个，就匹配尽可能多的到不匹配为止，如果采用懒惰模式，则就刚好匹配一个，不再多了。 代码 / 语法 匹配说明 *? 重复任意次，但尽可能的少重复 +? 重复1次或更多次，但尽可能少重复 ?? 重复0次或1次，但尽可能少重复 {n, m}? 重复n到m次，但尽可能少重复 {n,}? 重复n次以上，但尽可能少重复 import re m = re.match(r'(.*)', \"this is title>\") print m.group() m = re.match(r'(.*?)', \"this is title>\") print m.group() 输出 this is title> 分组与捕获 代码 / 语法 匹配说明 (?:) 只做匹配分组，不做结果展示，否则会有很多无用的分组结果 (?P) 对分组结果结果命令，使用命名获取 (?P=) 在后向引用时使用前面匹配到的分组名 In [1]: import re In [2]: re.match(r\"(?P\\w+):(?P\\d+)\", \"haha:1\").groups() Out[2]: ('haha', '1') In [3]: re.match(r\"(?P\\w+):(?P\\d+)\", \"haha:1\").groupdict() Out[3]: {'key': 'haha', 'value': '1'} In [4]: re.search(r\"((?P\\w+):(?P\\d+);)*\", \"haha:1;laal:2;\").groups() Out[4]: ('laal:2;', 'laal', '2') In [5]: re.search(r\"((?P\\w+):(?P\\d+);)*\", \"haha:1;laal:2;\").groupdict() Out[5]: {'key': 'laal', 'value': '2'} In [6]: re.search(r\"(?:(?P\\w+):(?P\\d+);)*\", \"haha:1;laal:2;\").groups() Out[6]: ('laal', '2') 但是有个问题就是匹配到的子串，只会出现一次，不能返回重复的结果，只会返回最终匹配的结果，需要使用 regex 来得到所有的匹配结果。 常用正则 对于常见的nginx日志配置格式 log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; 使用正则匹配规则就很简单 obj = re.compile(r'(?P.*?)- - \\[(?P.*?)\\] \"(?P.*?)\" (?P.*?) (?P.*?) \"(?P.*?)\" \"(?P.*?)\" \"(?P.*?)\"') 驼峰转下划线 # -*- coding: utf-8 -*- import re def convert_camel_to_snake(hump_str): \"\"\" 驼峰形式字符串转成下划线形式 :param hump_str: 驼峰形式字符串 :return: 字母全小写的下划线形式字符串 \"\"\" # 匹配正则，匹配小写字母和大写字母的分界位置 p = re.compile(r'([a-z]|\\d)([A-Z])') # 这里第二个参数使用了正则分组的后向引用 sub = re.sub(p, r'\\1_\\2', hump_str).lower() return sub if __name__ == '__main__': print(convert_camel_to_snake(\"AdId\")) print(convert_camel_to_snake(\"CampaignId\")) print(convert_camel_to_snake(\"coreUserID\")) print(convert_camel_to_snake(\"FromWhereYouGo\")) print(convert_camel_to_snake(\"PackageId\")) print(convert_camel_to_snake(\"SocketServer\")) print(convert_camel_to_snake(\"Python_Lib\")) 参考链接 正则表达式30分钟入门教程 Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-24 03:40:13 "},"official/json.html":{"url":"official/json.html","title":"json","keywords":"","body":"json 2016-01-13 更新 2017-03-18 更新 2017-10-22 更新 2018-06-21 2020-09-09 python这么强大的语言当然也可以用来处理json，两个主要的函数是json.dumps()和json.loads()分别用来将dist字典格式的Python数据编码为json数据格式字符串，和将json数据格式字符串解码为Python的数据格式。 还有 ujson 更快，simplejson 兼容性更强 分别有四个主要的函数 # 将 python 的数据格式转换为 json 字符串并存储到文件中 dump(obj, fp, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding='utf-8', default=None, sort_keys=False, **kw) # 将 python 的数据格式转换为 json 字符串 dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding='utf-8', default=None, sort_keys=False, **kw) # 从文件中读取 json 字符串并转换为python 的数据格式 load(fp, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw) # 将 json 字符串转换为 python 的数据格式 loads(s, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw) # coding=utf-8 import json data = { 'name' : 'ACME', 'shares' : 100, 'price' : 542.23, 'others': [\"first thing\",\"second thing\",\"third thing\"] } json_str = json.dumps(data) print json_str python_str = json.loads(json_str) print python_str print python_str[\"name\"] print python_str[\"price\"] print python_str[\"others\"][0] 保存为json_demo.py，运行，看一下结果。 可以看到第一行是json数据格式，第二行是Python的dist数据格式，也就可以正常的读写。 在将json数据格式转化为Python的数据格式了之后，为了更好的展示，可以使用pprint来代替原生的print，它会按照key的字幕顺序以一种更加美观的方式输出。 # coding=utf-8 import json from pprint import pprint data = { 'name' : 'ACME', 'shares' : 100, 'price' : 542.23, 'others': [\"first thing\",\"second thing\",\"third thing\"] } json_str = json.dumps(data) python_str = json.loads(json_str) pprint(python_str) 保存为json_demo_2.py,运行，看一下结果。 我们还可以将json数据解析成一个Python对象。 # coding=utf-8 import json class JSONObject: def __init__(self,d): self.__dict__=d data = { 'name' : 'ACME', 'shares' : 100, 'price' : 542.23, 'others': [\"first thing\",\"second thing\",\"third thing\"] } json_str = json.dumps(data) python_str = json.loads(json_str, object_hook=JSONObject) print isinstance(python_str,object) print python_str.name print python_str.price print python_str.others[1] 保存为json_object.py，运行，看一下结果。 在解码json的时候可以采用pprint来获得一个比较漂亮的输出，在编码json的时候也可以在dumps()函数里加上参数indent=X来缩进从而获得一个比较漂亮的输出。 2016-01-13 更新 在 Python 中 eval 和 str(unicode) 的功能也可以做 json 数据格式的转化 >>> data = { ... 'name' : 'ACME', ... 'shares' : 100, ... 'price' : 542.23, ... 'others': [\"first thing\",\"second thing\",\"third thing\"] ... } >>> json_str = str(data) >>> json_str \"{'price': 542.23, 'name': 'ACME', 'shares': 100, 'others': ['first thing', 'second thing', 'third thing']}\" >>> eval(json_str) {'price': 542.23, 'name': 'ACME', 'shares': 100, 'others': ['first thing', 'second thing', 'third thing']} 但是有一个问题，正确在 json 中为 true，但是在 Python 中为 True，失败在 json 中为 false ，但是在 Python 是为 False。 >>> data = \"{'name':'ACMA','status':false}\" >>> eval(data) Traceback (most recent call last): File \"\", line 1, in File \"\", line 1, in NameError: name 'false' is not defined 对于 json 数据格式的操作还是让专业的库来干吧。 2017-03-18 更新 json 格式数据与 Python 中的 字典 dict 并不完全一致，json 只能是双引号包围的字符串，而 Python 中的字符串可以用双引号也可以用单引号。 +-------------------+---------------+ | Python | JSON | +===================+===============+ | dict | object | +-------------------+---------------+ | list, tuple | array | +-------------------+---------------+ | str, unicode | string | +-------------------+---------------+ | int, long, float | number | +-------------------+---------------+ | True | true | +-------------------+---------------+ | False | false | +-------------------+---------------+ | None | null | +-------------------+---------------+ JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]}) # 将字典格式转换为 json 字符串 JSONDecoder().decode('{\"foo\": [\"bar\", \"baz\"]}') # 将 json 字符串转换为字典格式 2017-10-22 更新 json 和 dict 还有两个地方不一样 dict 在所有的键值对之后还可以有逗号，json 在所有的键值对最后没有逗号 dict 的键可以是数字，json 的键不能是数字，只能是字符串 2018-06-21 json.dumps(obj, indent=4) 能够输出一个格式化的字符串，有换行有缩进。 json.dumps(obj, separators=(',',':')) 能够对输出字符串进行一个简单的压缩，取消空格.因为默认是 (', ', ': ') json.dumps(obj, ensure_ascii=False) 能够输出 utf-8 格式的中文即可见的中文，而非 Unicode 格式的中文 \\uXXXX 2020-09-09 正常的 json 字符串像这样 '{\"price\": 542.23, \"name\": \"ACME\", \"shares\": 100, \"others\": [\"first thing\", \"second thing\", \"third thing\"]}' 都是没问题的，但是如果在 json 对象中，key 或者 value 里存在控制字符，就会出现 Invalid Control Character 的 ValueError。 什么是控制字符？ACSII 码表，排名前三十二位和最后一位的字符就是控制字符，包括 \\t, \\n, \\r 等。 ASCII码一览表 出现控制字符怎么办？ 比如这样的 json 字符串 '{\"price\": 542.23, \"name\": \"ACME\", \"sh\\rares\": 100, \"others\": [\"first thing\", \"second\\t thing\", \"third\\n thing\"]}' 不要惊慌，在解析的时候，传入参数 strict=False 即可。 In [28]: s = '{\"price\": 542.23, \"name\": \"ACME\", \"shares\": 100, \"others\": [\"first thing\", \"second thing\", \"third thing\"]}' In [29]: json.loads(s) Out[29]: {u'name': u'ACME', u'others': [u'first thing', u'second thing', u'third thing'], u'price': 542.23, u'shares': 100} In [30]: s = '{\"price\": 542.23, \"name\": \"ACME\", \"sh\\rares\": 100, \"others\": [\"first thing\", \"second\\t thing\", \"third\\n thing\"]}' In [31]: json.loads(s) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in () ----> 1 json.loads(s) /Users/bytedance/miniconda/envs/byted/lib/python2.7/json/__init__.pyc in loads(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw) 337 parse_int is None and parse_float is None and 338 parse_constant is None and object_pairs_hook is None and not kw): --> 339 return _default_decoder.decode(s) 340 if cls is None: 341 cls = JSONDecoder /Users/bytedance/miniconda/envs/byted/lib/python2.7/json/decoder.pyc in decode(self, s, _w) 362 363 \"\"\" --> 364 obj, end = self.raw_decode(s, idx=_w(s, 0).end()) 365 end = _w(s, end).end() 366 if end != len(s): /Users/bytedance/miniconda/envs/byted/lib/python2.7/json/decoder.pyc in raw_decode(self, s, idx) 378 \"\"\" 379 try: --> 380 obj, end = self.scan_once(s, idx) 381 except StopIteration: 382 raise ValueError(\"No JSON object could be decoded\") ValueError: Invalid control character at: line 1 column 38 (char 37) In [32]: json.loads(s, strict=False) Out[32]: {u'name': u'ACME', u'others': [u'first thing', u'second\\t thing', u'third\\n thing'], u'price': 542.23, u'sh\\rares': 100} 还需要注意两点 控制字符无论在 json 的 key 或者 value 中，都有问题。 如果不是在 json 的字符串类型中有控制字符，是可以正常解析的，像在 json 的两个 key 之间是可以有正常的换行符，比如这样的字符串 '\\n{\"price\": 542.23,\\n \"name\": \"ACME\", \\t\"shares\": 100, \"others\": [\"first thing\", \"second thing\",\\n \"third thing\"]}' 如果不是手动换行符，而是出现了换行，也是一样的换行符，主要是在 json 的每个元素里，不能有换行符。 In [34]: s = '\\n{\"price\": 542.23,\\n \"name\": \"ACME\", \\t\"shares\": 100, \"others\": [\"first thing\", \"second thing\",\\n \"third thing\"]}' In [35]: json.loads(s) Out[35]: {u'name': u'ACME', u'others': [u'first thing', u'second thing', u'third thing'], u'price': 542.23, u'shares': 100} In [37]: s= \"\"\"{\"price\": 542.23, \"name\": \"ACME\", \"shares\": 100, \"others\": [\"first thing\", \"second ...: thing\", \"third thing\"]}\"\"\" In [38]: s Out[38]: '{\"price\": 542.23, \"name\": \"ACME\", \"shares\": 100, \"others\": [\"first thing\", \"second \\nthing\", \"third thing\"]}' In [39]: json.loads(s) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) in () ----> 1 json.loads(s) /Users/bytedance/miniconda/envs/byted/lib/python2.7/json/__init__.pyc in loads(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw) 337 parse_int is None and parse_float is None and 338 parse_constant is None and object_pairs_hook is None and not kw): --> 339 return _default_decoder.decode(s) 340 if cls is None: 341 cls = JSONDecoder /Users/bytedance/miniconda/envs/byted/lib/python2.7/json/decoder.pyc in decode(self, s, _w) 362 363 \"\"\" --> 364 obj, end = self.raw_decode(s, idx=_w(s, 0).end()) 365 end = _w(s, end).end() 366 if end != len(s): /Users/bytedance/miniconda/envs/byted/lib/python2.7/json/decoder.pyc in raw_decode(self, s, idx) 378 \"\"\" 379 try: --> 380 obj, end = self.scan_once(s, idx) 381 except StopIteration: 382 raise ValueError(\"No JSON object could be decoded\") ValueError: Invalid control character at: line 1 column 84 (char 83) Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-24 10:10:53 "},"official/logging.html":{"url":"official/logging.html","title":"logging","keywords":"","body":"logging 常用配置 简单使用 使用技巧 打印异常堆栈 日志滚动 标准的输出日志库，比每次用 print 输出不知道高到哪里去了。 常用配置 使用日志模块，如果直接使用 logging.info 使用的是 root_logger ，最好是使用 logging.getLogger(__name__) 拿到一个当前的 logger 使用。 无论是用 root_logger 还是 current_logger 如果不进行配置的话，默认是没有任何输出的。 logging 如果不配置是没有数据输出的，但是如果不想写这么长的配置怎么办呢？直接使用 logging.basicConfig() 进行一个简单的基础配置。 logging.basicConfig( level=logging.INFO, format='%(name)-25s %(asctime)s %(levelname)-8s %(lineno)-4d %(message)s', datefmt='[%Y %b %d %a %H:%M:%S]' ) 或者是 # -*- coding: utf-8 -*- import logging from logging.config import dictConfig logging_config = { \"version\": 1, \"disable_existing_loggers\": False, \"formatters\": {\"default\": {\"format\": \"%(asctime)s %(levelname)-8s %(filename)s:%(lineno)d %(message)s\"}}, \"handlers\": { \"console\": {\"level\": \"INFO\", \"class\": \"logging.StreamHandler\", \"formatter\": \"default\"}, \"file_logger\": {\"level\": \"INFO\", \"class\": \"logging.FileHandler\", \"formatter\": \"default\", \"filename\": \"douban_spider.log\"} }, \"root\": {\"handlers\": [\"file_logger\", \"console\"], \"level\": \"INFO\"}, } dictConfig(logging_config) logger = logging.getLogger(__name__) 一般常用的 logging 包括一个文件写入和一个屏幕输出 # -*- coding: utf-8 -*- import sys import logging logger = logging.getLogger(\"Socket Logging\") formatter = logging.Formatter('%(name)-12s %(asctime)s %(levelname)-8s %(lineno)-4d %(message)s', '%Y %b %d %a %H:%M:%S',) file_handler = logging.FileHandler(\"SocketServer.log\") file_handler.setFormatter(formatter) logger.addHandler(file_handler) stream_handler = logging.StreamHandler(sys.stderr) stream_handler.setFormatter(formatter) logger.addHandler(stream_handler) logger.setLevel(logging.DEBUG) 也可以这样配置日志 # coding=utf-8 import logging def main(): # Configure the logging system logging.basicConfig( filename='app.log', level=logging.ERROR, format='%(levelname)s:%(asctime)s:%(message)s' ) # Variables (to make the calls that follow work) hostname = 'www.python.org' item = 'spam' filename = 'data.csv' mode = 'r' # Example logging calls (insert into your program) logging.critical('Host %s unknown', hostname) logging.error(\"Couldn't find %r\", item) logging.warning('Feature is deprecated') logging.info('Opening file %r, mode=%r', filename, mode) logging.debug('Got here') if __name__ == '__main__': main() 简单使用 #coding=utf-8 import logging import sys LEVELS = {'debug': logging.DEBUG, 'info': logging.INFO, 'warning': logging.WARNING, 'error': logging.ERROR, 'critical': logging.CRITICAL} if len(sys.argv) > 1: level_name = sys.argv[1] level = LEVELS.get(level_name, logging.NOTSET) logging.basicConfig(level=level) logging.debug('This is a debug message') logging.info('This is an info message') logging.warning('This is a warning message') logging.error('This is an error message') logging.critical('This is a critical error message') logging 共分五个 log 等级，默认输出的 Level 为 warning 等级，可以设定为其他等级就可以将代码中的每一个等级大于等于 Level 的问题都输出。 #coding=utf-8 import sys import logging logger = logging.getLogger(\"Test Logging\") formatter = logging.Formatter('%(name)-12s %(asctime)s %(levelname)-8s %(lineno)-4d %(message)s', '%Y%b%d %a %H:%M:%S') file_handler = logging.FileHandler(\"test.log\") file_handler.setFormatter(formatter) file_handler.setLevel(logging.DEBUG) stream_handler = logging.StreamHandler(sys.stderr) stream_handler.setFormatter(formatter) stream_handler.setLevel(logging.WARNING) logger.addHandler(file_handler) logger.addHandler(stream_handler) logger.setLevel(logging.DEBUG) logger.debug('This is a debug message') logger.info('This is an info message') logger.warning('This is a warning message') logger.error('This is an error message') logger.removeHandler(stream_handler) logger.critical('This is a critical error message') 设定 log 的的格式，和 log 的输出位置，可以在屏幕上，也可以输出到文件中，可以将不同地方的 log 输出等级设为不同。 关于输出的 log 格式 格式 用处 %(name)s Logger的名字 %(levelno)s 数字形式的日志级别 %(levelname)s 文本形式的日志级别 %(pathname)s 调用日志输出函数的模块的完整路径名，可能没有 %(filename)s 调用日志输出函数的模块的文件名 %(module)s 调用日志输出函数的模块名 %(funcName)s 调用日志输出函数的函数名 %(lineno)d 调用日志输出函数的语句所在的代码行 %(created)f 当前时间，用UNIX标准的表示时间的浮点数表示 %(relativeCreated)d 输出日志信息时的，自Logger创建以来的毫秒数 %(asctime)s 字符串形式的当前时间。默认格式是“2003-07-08 16:49:45,896”。逗号后面的是毫秒 %(thread)d 线程ID。可能没有 %(threadName)s 线程名。可能没有 %(process)d 进程ID。可能没有 %(message)s 用户输出的消息 使用技巧 打印异常堆栈 可以使用 logger.exception 代替 logger.error ，日志等级也是 error, 但是会打印出异常的堆栈信息 关于 logger 输出异常堆栈，无论使用 logger.info 或者 logger.error 输出格式都是一样的，只是日志等级不一样但是有时在输出异常的时候，我们不只是需要知道异常名称，还需要知道异常的上下文，堆栈信息等特别是在多线程中，子线程的异常不会被主线程捕获输出，只能通过日志打印出来 示例代码 # coding=utf-8 import sys import logging logger = logging.getLogger(__name__) formatter = logging.Formatter('%(name)-12s %(asctime)s %(levelname)-8s %(lineno)-4d %(message)s', '%Y %b %d %a %H:%M:%S',) stream_handler = logging.StreamHandler(sys.stderr) stream_handler.setFormatter(formatter) logger.addHandler(stream_handler) logger.setLevel(logging.DEBUG) if __name__ == '__main__': logger.info(\"main start...\") try: 1 / 0 except Exception as e: logger.exception(\"error %s\", e) logger.info(\"main end.\") 对比一下输出的日志即可看出。 使用 logger.error 的效果 __main__ 2019 May 25 Sat 22:23:36 INFO 16 main start... __main__ 2019 May 25 Sat 22:23:36 ERROR 20 error integer division or modulo by zero __main__ 2019 May 25 Sat 22:23:36 INFO 21 main end. 使用 logger.exception 的效果 __main__ 2019 May 25 Sat 22:23:52 INFO 16 main start... __main__ 2019 May 25 Sat 22:23:52 ERROR 20 error integer division or modulo by zero Traceback (most recent call last): File \"code/logging_exception.py\", line 18, in 1 / 0 ZeroDivisionError: integer division or modulo by zero __main__ 2019 May 25 Sat 22:23:52 INFO 21 main end. 日志滚动 如果需要使用一个定时日志切割的功能，不需要任何的其他工具，用 logging.handlers.TimedRotatingFileHandler 即可。 Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-24 10:10:53 "},"official/ast.html":{"url":"official/ast.html","title":"ast","keywords":"","body":"ast 解析 反解析 安全的执行 ast 是 python 自带的 语法树生成器，可以用来解析 python 代码，生成抽象语法树。 编译器的编译流程 +---------+ +------------+ +------------------------+ +----------------------+ +---------------+ | 源代码 +-->+ 语法分析树 +-->+ 抽象语法树 +-->+ 控制流图 +-->+ 代码对象 + | | | Parse Tree | | Abstract Syntax Tree | | Control Flow Graph | | Code Object | +---------+ +------------+ +------------------------+ +----------------------+ +---------------+ 生成抽象语法树的过程就是 ast 实现的过程，我们可以通过 ast 来访问和修改抽象语法树。 解析 # coding=utf-8 import ast code = \"\"\" def add(a, b): return a + b add(1, 2) \"\"\" print \"hello world\" print ast.parse(code) print ast.dump(ast.parse(code)) 其实 ast.parse 的核心是直接使用 compile 编译 def parse(source, filename='', mode='exec'): \"\"\" Parse the source into an AST node. Equivalent to compile(source, filename, mode, PyCF_ONLY_AST). \"\"\" return compile(source, filename, mode, PyCF_ONLY_AST) 解析生成的结构体有 _ast.Module, _ast.Assign, _ast.Str 等,我们查看 Module 的结构 Module(body=[FunctionDef(name='add', args=arguments(args=[Name(id='a', ctx=Param()), Name(id='b', ctx=Param())], vararg=None, kwarg=None, defaults=[]), body=[Return(value=BinOp(left=Name(id='a', ctx=Load()), op=Add(), right=Name(id='b', ctx=Load())))], decorator_list=[]), Expr(value=Call(func=Name(id='add', ctx=Load()), args=[Num(n=1), Num(n=2)], keywords=[], starargs=None, kwargs=None))]) 我们可以将其中的 加法操作符换成乘法操作符 # coding=utf-8 import ast code = \"\"\" def add(a, b): return a + b print add(1, 2) \"\"\" class CrazyTransformer(ast.NodeTransformer): def visit_BinOp(self, node): print node.__dict__ node.op = ast.Mult() print node.__dict__ return node def main(): module = ast.parse(code) exec compile(module, '', 'exec') transformer = CrazyTransformer() multi = transformer.visit(module) exec compile(multi, '', 'exec') if __name__ == '__main__': main() 反解析 ast 只管杀不管埋，所以讲抽象语法树再转换为源代码还要我们自己处理一下，也可以用其他的库。 主要有一个 unparse.py 的单文件脚本就可以用。 或者是 codegen, astunparse, astor 等库 # coding=utf-8 import ast import unparse code = \"\"\" def add(a, b): return a + b print add(1, 2) \"\"\" class CrazyTransformer(ast.NodeTransformer): def visit_BinOp(self, node): node.op = ast.Mult() return node def back(): module = ast.parse(code) transformer = CrazyTransformer() multi = transformer.visit(module) unparse.Unparser(multi) if __name__ == '__main__': back() 还要其他的比如 # coding=utf-8 import ast import codegen import astunparse import astor code = \"\"\" data = { \"key\": \"value\", \"list\": [1,2,3] } def add(a, b): return a + b print add(1, 2) \"\"\" module = ast.parse(code) print codegen.to_source(module) print astunparse.unparse(module) print astor.to_source(module) 有一个好消息是 3.9 开始支持 ast.unparse 反解析函数。 安全的执行 在 Python 中有 eval 方法,但是一般如果直接调用 eval 执行的话，会有安全风险，可以试下 ast.literal_eval 进行安全的代码执行。 这个代码执行可以厉害了୧(๑•̀◡•́๑)૭， 只能含有 Python 基本数据类型，数字，字符串，列表，字典，元组，布尔值，None 和复数。 &#x1F602;，复数？是不是突然觉得很突然，为什么会有复数？你是不是已经把复数是啥给忘了？1+2j 就是复数。 def literal_eval(node_or_string): \"\"\" Safely evaluate an expression node or a string containing a Python expression. The string or node provided may only consist of the following Python literal structures: strings, numbers, tuples, lists, dicts, booleans, and None. \"\"\" _safe_names = {'None': None, 'True': True, 'False': False} if isinstance(node_or_string, basestring): node_or_string = parse(node_or_string, mode='eval') if isinstance(node_or_string, Expression): node_or_string = node_or_string.body def _convert(node): if isinstance(node, Str): return node.s elif isinstance(node, Num): return node.n elif isinstance(node, Tuple): return tuple(map(_convert, node.elts)) elif isinstance(node, List): return list(map(_convert, node.elts)) elif isinstance(node, Dict): return dict((_convert(k), _convert(v)) for k, v in zip(node.keys, node.values)) elif isinstance(node, Name): if node.id in _safe_names: return _safe_names[node.id] elif isinstance(node, BinOp) and \\ isinstance(node.op, (Add, Sub)) and \\ isinstance(node.right, Num) and \\ isinstance(node.right.n, complex) and \\ isinstance(node.left, Num) and \\ isinstance(node.left.n, (int, long, float)): left = node.left.n right = node.right.n if isinstance(node.op, Add): return left + right else: return left - right raise ValueError('malformed string') return _convert(node_or_string) 源码很简单，可以直接看代码，或者手动测试。 赋值操作不能用，加减乘除不能用，比较运算不能用，连集合都不能用。复数可以用，负数也可以，但是正数就不行。 好消息是从 Python 3.2 开始支持集合。 # -*- coding: utf-8 -*- import ast if __name__ == '__main__': # 赋值操作不能有 # print ast.literal_eval(\"a=1\") # print eval(\"a=1\") # a = 1 # 加减乘除都不能有 # print ast.literal_eval(\"1+1\") # print eval(\"1+1\") # print ast.literal_eval(\"1==1\") print eval(\"1==1\") print ast.literal_eval(\"1\") print ast.literal_eval(\"None\") # 连集合都不能有 # print ast.literal_eval(\"{1,2,4}\") # print ast.literal_eval(\"set([1])\") # print ast.literal_eval(\"[1,2,{'1', 2, '2,3,4'}, [4,5,'6']]\") # print [1,2,{'1', 2, '2,3,4'}, [4,5,'6']] print ast.literal_eval(\"[1,2,3,{2:3}]\") # 连最终结果是一个list也不行 # print ast.literal_eval(\"list([1,2,3])\") print list([1, 2, 3]) # print ast.literal_eval(\"[1,2+3]\") # 复数可以有，负数也可以有 print ast.literal_eval(\"1+2j\") print ast.literal_eval(\"-2\") # print ast.literal_eval(\"--2\") # 正数就不行 # print ast.literal_eval(\"+2\") # print ast.literal_eval(\"++2\") Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-28 02:32:00 "},"official/ply.html":{"url":"official/ply.html","title":"ply","keywords":"","body":"ply 前言 Lex&Yacc Lex 示例 开始的开始 学一点正则 语法解析 Python Lex-Yacc, 即 Python 版的 Lex-Yacc 工具，有了它们，你永远不需要自己手动写一个解析程序。 如果你在 *nix 电脑上，一般自带 Lex 和 Yacc ，try it youself . 前言 在很多年前，在大学上编译原理的时候，当时讲到编译流程，有什么词法生成树，句法生成树，抽象语法树什么之类的，再往后就没认真听了。 然后大作业是自己实现一个语法解析器，当时什么也不会，就知道什么遇到数字就继续读取，遇到符号就判断，可以循环判断和读取，用大量的 if,else 写了巨复杂的语法分析。 最近也在实现一个简单的输入规则分析，这次不是用 if,else 了，而是用的正则表达式，通过正则匹配获取结果。 其实在当时做大作业的时候，就已经有同学用 yacc 之类的分析工具，可以我到现在都不会用。 前段时间也用过 ast 抽象语法树之后，这一切终于都理顺了。 一段输入，首先需要被读取为字符串，（编码解码先不论），然后通过语法分析，（通过 if,else 判断，或者正则表达式解析，或者 yacc 这样的工具分析），然后生成抽象语法树，（这时已经生成对应的语法结构块），最后通过控制流程补充完善，得到执行对象。 Lex&Yacc Lex 和 Yacc 是什么？ Lex 和 Yacc 是一对好兄弟&#x1F46C;，一般搭配使用。Lex 是分词器，它用来根据规则对输入数据进行匹配操作。Yacc 是根据分词结果进行解析。 Lex 示例 开始的开始 lex_start.lt %{ #include %} %% stop printf(\"Stop command received\"); start printf(\"Start command reveived\"); %% 这是我们的第一个 lex 代码，注意 因为我们需要使用 printf 进行输出，引入了 stdio.h 库，学过 C 语言的同学应该对此很熟悉，使用 %{ 和 %} 围起来的部分将原样导出，它们看起来并不对称。 使用 %% 和 %% 围起来的段落，是我们的 lex 语法部分，第一句表示当输入流中读到 stop 时，执行 printf(\"Stop command received\");, 第二句则是对 start 的操作。 使用 lex lex_start.lt 对其进行编译，将会生成 lex.yy.c 的 C 语言文件，然后使用 cc lex.yy.c -o lex_start -ll 生成可执行文件 lex_start 执行结果，当遇到 start 时，输出 Start command reveived,当遇到 stop 时，输出 Stop command received, 这里区分大小写，遇到其他值，则原样输出。输入多少，输出多少，只有大小写完全匹配 start 和 stop 的时候才会有不同的回应。 $ ./lex_start start Start command reveived stop Stop command received yes yes no no ! ! ^C 这里的 lex 更像一门 模板语言，可以引入 C 语言的一些功能，自己的主要功能是为了做匹配和操作。 学一点正则 这些正则匹配规则都知道吧 [0123456789]+ # 表示一个或多个数字 [0-9]+ # 表示一个或多个数字 [a-z] # 表示单个a-z的字母 [a-z]* # 表示0个或多个字母 所以我们的正则匹配就开始了 lex_regex.lt %{ #include %} %% [0-9]+ printf(\"NUMBER\\n\"); [a-zA-Z][a-zA-Z0-9]* printf(\"WORD\\n\"); %% 同样的编译运行查看结果。 $ lex lex_regex.lt $ cc lex.yy.c -o lex_regex -ll $ ./lex_regex 2334 NUMBER dervr WORD str1 WORD 123avc NUMBER WORD -12 -NUMBER 12.43 NUMBER .NUMBER a@a WORD @WORD ^C 看起来一切都很正常，数字和变量的定义都没问题.但是后面几个怎么看起来就不正常了，包括负数，小数，异常值。 语法解析 虽然上面&#x1F446;的词法解析有点小瑕疵，但是不影响，我们继续进行下一步语法解析。 如何使用Lex/YACC Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-24 10:10:53 "},"official/threading.html":{"url":"official/threading.html","title":"threading","keywords":"","body":"threading 创建多线程的几种方法 参数传入 派生子类 高阶使用 生产者-消费者模式 八个线程 资源锁定 本地变量 线程数量 线程池 多线程的结束 多线程的异常输出 线程定时器 创建多线程的几种方法 threading 库主要有两种创建多线程的方法，和 Java 中的多线程类似，一种是面向方法的，一种是面向对象的。 创建一个 threading.Thread 的实例，将子线程逻辑调用函数作为参数传入，然后调用 start 方法创建子线程。 从 threading.Thread 派生出一个子类，实现这个类的 run 方法，在 run 方法中实现子线程逻辑，然后创建这个子类的实例。 还有第三种，创建一个 threading.Thread 的实例，传给它一个可调用的类实例，其实原理是和第一种一样的。 参数传入 # coding=utf-8 import threading from time import ctime,sleep def loop(nloop,nsec): print \"loop\",nloop,\" start at: \",ctime() sleep(nsec) print \"loop\",nloop,\"end at: \",ctime() print \"all start at: \",ctime() loops = [4,2] threads = [] nloops = range(len(loops)) #创建两个线程 for i in nloops: t = threading.Thread(target=loop,args=(i,loops[i])) threads.append(t) #让两个线程同时开始 for i in nloops: threads[i].start() print \"all end at: \",ctime() 保存为 threading_start.py，运行，看一下结果。 $ python threading_start.py all start at: Wed Oct 7 15:13:32 2020 loop 0 start at: Wed Oct 7 15:13:32 2020 loop 1 start at: Wed Oct 7 15:13:32 2020 all end at: Wed Oct 7 15:13:32 2020 loop 1 end at: Wed Oct 7 15:13:34 2020 loop 0 end at: Wed Oct 7 15:13:36 2020 两个分别耗时2秒和4秒的函数同时开始，然后总共耗时还是4秒，程序运行结束。 这里需要注意，按照代码逻辑主线程在唤起两个子线程之后，其实已经运行至最后一行并输出结束时间 但是此时程序还未结束，直至所有的子线程运行结束之后，主线程才真正结束。 接下来是第三种使用实例调用的方式 # coding=utf-8 import threading from time import ctime,sleep class ThreadFunc(object): def __init__(self, func, args, name=\"\"): self.args = args self.func = func self.name = name def __call__(self): apply(self.func, self.args) def loop(nloop,nsec): print \"loop\",nloop,\" start at: \",ctime() sleep(nsec) print \"loop\",nloop,\"end at: \",ctime() print \"all start at: \",ctime() loops = [4,2] threads = [] nloops = range(len(loops)) for i in nloops: t = threading.Thread(target=ThreadFunc(loop,(i,loops[i]),loop.__name__)) threads.append(t) for i in nloops: threads[i].start() for i in nloops: threads[i].join() print \"all end at: \",ctime() 保存为 threading_class.py，运行，看一下结果。 这里虽然传入的是对象实例，但是其实还是按照参数传入的方式进行的，主要的差异在于主线程被子线程阻塞，在子线程都运行结束之后，在运行至最后一行输出结束时间。 为什么在这里主线程会阻塞至子线程运行结束呢？因为在调用 start 函数唤起子线程之后，我们还调用了 join 函数，让子线程加入主线程，让主线程强行等待。 这里其实有一个小细节，第一个线程 join 方法之后，主线程已经进入阻塞状态，那么为什么第二个线程还能继续 join 呢？因为 jion 之后，子线程会阻塞主线程，或者说调用的线程，但是不影响其他的线程，所以其他的子线程可以继续 join其他子线程的创建和启动都是在主线程中执行的，但是其他子线程的 join 操作，其实是在子线程中执行的 #coding=utf-8 import threading from time import ctime,sleep class ThreadFunc(object): def __init__(self, func ,args,name=\"\"): self.args = args self.func = func self.name = name def __call__(self): apply(self.func,self.args) def loop(nloop,nsec): print \"loop\",nloop,\" start at: \",ctime() sleep(nsec) print \"loop\",nloop,\"end at: \",ctime() print \"all start at: \",ctime() loops = [4,2] threads = [] nloops = range(len(loops)) for i in nloops: t = threading.Thread(target=ThreadFunc(loop,(i,loops[i]),loop.__name__)) threads.append(t) for i in nloops: threads[i].start() # for i in nloops: # threads[i].join() # print i, \"is joined at: \", ctime() # 甚至一个一个 join threads[0].join() print \"0 is joined at: \", ctime() threads[1].join() print \"1 is joined at: \", ctime() print \"all end at: \",ctime() 看下结果，join 调用都是正常的，但是输出 join 时间都在主线程里被阻塞到最后了。 $ python code/threading_class_2.py all start at: Wed Oct 7 15:34:05 2020 loop 0loop 1 start at: Wed Oct 7 15:34:05 2020 start at: Wed Oct 7 15:34:05 2020 loop 1 end at: Wed Oct 7 15:34:07 2020 loop 0 end at: Wed Oct 7 15:34:09 2020 0 is joined at: Wed Oct 7 15:34:09 2020 1 is joined at: Wed Oct 7 15:34:09 2020 all end at: Wed Oct 7 15:34:09 2020 派生子类 # coding=utf-8 import threading from time import ctime,sleep class MyThread(threading.Thread): def __init__(self, func, args, name=\"\"): threading.Thread.__init__(self) self.name = name self.func = func self.args = args def run(self): apply(self.func, self.args) def loop(nloop,nsec): print \"loop\",nloop,\" start at: \",ctime() sleep(nsec) print \"loop\",nloop,\"end at: \",ctime() print \"all start at: \",ctime() loops = [4,2] threads = [] nloops = range(len(loops)) for i in nloops: t = MyThread(loop,(i,loops[i]),loop.__name__) threads.append(t) for i in nloops: threads[i].start() for i in nloops: threads[i].join() print \"all end at: \",ctime() 保存为threading_class_MyThread.py，运行，看一下结果是和我们预期的一样。 上面的代码如果还是有函数传入的部分，如果有些理解混淆的话，也可以写成这样 #coding=utf-8 import threading from time import ctime,sleep class ThreadDemo(threading.Thread): def __init__(self, nloop, nsec, name=\"\"): threading.Thread.__init__(self) self.name = name self.nloop = nloop self.nsec = nsec def run(self): print \"loop\", self.nloop, \"start at: \", ctime() sleep(self.nsec) print \"loop\", self.nloop, \"end at: \", ctime() print \"all start at: \",ctime() loops = [4,2] threads = [] nloops = range(len(loops)) for i in nloops: t = ThreadDemo(i, loops[i], \"loop\") threads.append(t) for i in nloops: threads[i].start() for i in nloops: threads[i].join() print \"all end at: \", ctime() 这里为什么创建子类实例了之后，还是需要调用 start 方法呢？因为子线程 threading.Thread 的唤起就是需要使用 start 方法。 具体运行的子线程逻辑无论是参数传入，还是子类覆盖重写，子线程启动都需要 start 一下，其实看下库代码就能够理解了。 class Thread(_Verbose): def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, verbose=None): \"\"\"This constructor should always be called with keyword arguments. Arguments are: *group* should be None; reserved for future extension when a ThreadGroup class is implemented. *target* is the callable object to be invoked by the run() method. Defaults to None, meaning nothing is called. *name* is the thread name. By default, a unique name is constructed of the form \"Thread-N\" where N is a small decimal number. *args* is the argument tuple for the target invocation. Defaults to (). *kwargs* is a dictionary of keyword arguments for the target invocation. Defaults to {}. If a subclass overrides the constructor, it must make sure to invoke the base class constructor (Thread.__init__()) before doing anything else to the thread. \"\"\" assert group is None, \"group argument must be None for now\" _Verbose.__init__(self, verbose) if kwargs is None: kwargs = {} self.__target = target self.__name = str(name or _newname()) self.__args = args self.__kwargs = kwargs self.__daemonic = self._set_daemon() self.__ident = None self.__started = Event() self.__stopped = False self.__block = Condition(Lock()) self.__initialized = True # sys.stderr is not stored in the class like # sys.exc_info since it can be changed between instances self.__stderr = _sys.stderr def run(self): \"\"\"Method representing the thread's activity. You may override this method in a subclass. The standard run() method invokes the callable object passed to the object's constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively. \"\"\" try: if self.__target: self.__target(*self.__args, **self.__kwargs) finally: # Avoid a refcycle if the thread is running a function with # an argument that has a member that points to the thread. del self.__target, self.__args, self.__kwargs 这里还有一个小细节，我们其实有连续三次的循环 append,start,join 操作，那么能否放在一个循环里呢？将 append 和 start 放一起是可以的，因为 start 唤起子线程之后，不会阻塞主线程，可以继续 start 下一个但是不能将 join 也放一起，因为 join 之后之后会阻塞，只有下一个 join 才能继续如果 join 之后是创建新的子线程或者 start 操作都是会被阻塞的，因为这些操作是在主线程里，就没用到多线程，而是变成了同步操作 #coding=utf-8 import threading from time import ctime,sleep class ThreadDemo(threading.Thread): def __init__(self, nloop, nsec, name=\"\"): threading.Thread.__init__(self) self.name = name self.nloop = nloop self.nsec = nsec def run(self): print \"loop\", self.nloop, \"start at: \", ctime() sleep(self.nsec) print \"loop\", self.nloop, \"end at: \", ctime() print \"all start at: \",ctime() loops = [4,2] threads = [] nloops = range(len(loops)) for i in nloops: t = ThreadDemo(i, loops[i], \"loop\") threads.append(t) t.start() for i in nloops: threads[i].join() print \"all end at: \",ctime() 或者参数传入的方式 # coding=utf-8 import threading from time import ctime,sleep def loop(nloop,nsec): print \"loop\",nloop,\" start at: \",ctime() sleep(nsec) print \"loop\",nloop,\"end at: \",ctime() print \"all start at: \",ctime() loops = [4,2] threads = [] nloops = range(len(loops)) #创建两个线程 for i in nloops: t = threading.Thread(target=loop,args=(i,loops[i])) threads.append(t) #让两个线程同时开始 for i in nloops: threads[i].start() #将两个线程加入主线程 #如果将join和start在一起的话 #就会阻塞主线程的执行 #没有产生另一个子线程 #所以并没有开启多线程 #还是一个线程一个线程的执行 for i in nloops: threads[i].join() print \"all end at: \",ctime() 保存为threading_demo.py，运行，看一下结果。 高阶使用 Python 中还要一个较为基础的 thread 库，这个库里还需要我们自己的去设定锁，并且在主线程里阻塞主线程的进行来判断锁是否已经释放, threading 是比 thread 更高级易于操作的多线程库。 在 threading 库中创建的子线程都是非守护线程，因为创建的子线程的 Daemon 属性继承父线程，而我们一般直接运行 Python 代码都是非守护线程的方式。 对于非守护线程，主线程会等待子线程结束再结束。而如果是一个守护线程，主线程运行结束之后就会立即终止，并不关心子线程的运行情况。 我们可以通过 threading.Thread.setDaemon(True) 的方式来将子线程设置为守护线程 #coding=utf-8 import threading from time import ctime,sleep def loop(nloop,nsec): print \"loop\",nloop,\" start at: \",ctime() sleep(nsec) print \"loop\",nloop,\"end at: \",ctime() print \"all start at: \",ctime() loops = [4,2] threads = [] nloops = range(len(loops)) #创建两个线程 for i in nloops: t = threading.Thread(target=loop,args=(i,loops[i])) t.setDaemon(True) threads.append(t) #让两个线程同时开始 for i in nloops: threads[i].start() print \"all end at: \",ctime() 运行结果就是只有开始，没有结束. $ python threading_start_daemon.py all start at: Thu Oct 8 10:28:57 2020 loop 0loop 1 start at: Thu Oct 8 10:28:57 2020 all end at: Thu Oct 8 10:28:57 2020 start at: Thu Oct 8 10:28:57 2020 多线程中，子线程创建后，start 即开始子线程，主线程继续进行，join 即阻塞主线程，等待子线程结束后再继续主线程。在手动的将子线程加入(join)到主线程中后，主线程就会等待子线程全部结束才会继续之后的程序。在 join 被加入到主线程之后，虽然主线程被阻塞，但是并不影响其他线程，其他线程可以继续 join 到主线程。在未设置守护线程，未 join 到主线程中的时候，主线程会先运行结束，但是主程序未结束，等待子线程结束后程序才会结束。守护线程的意思就是说这个线程独立于主线程，主线程可以先于守护线程结束而不用等候守护线程结束。 对于守护线程，也可以使用 join 方法，同样可以阻塞主线程。 这里需要注意，只能对未启动(start)的子线程设置守护进程，对于已经启动子线程不能再设置为守护线程 # -*- coding: utf-8 -*- from threading import Thread import os import time def sleeper(name, seconds): print 'starting child process with id: ', os.getpid() print 'parent process:', os.getppid() print 'sleeping for %s ' % seconds time.sleep(seconds) print \"%s done sleeping\" % name if __name__ == '__main__': print \"in parent process (id %s)\" % os.getpid() p = Thread(target=sleeper, args=('bob', 5)) print 'daemon?', p.isDaemon() p.setDaemon(not p.isDaemon()) print 'daemon?', p.isDaemon() p.start() print \"in parent process after child process start\" print \"parent process about to join child process\" p.join() print \"in parent process after child process join\" print \"parent process exiting with id \", os.getpid() print \"The parent's parent process:\", os.getppid() 或者这样 #coding=utf-8 import threading from time import ctime,sleep class DaemonThreadDemo(threading.Thread): def __init__(self, nloop, nsec, name=\"\"): threading.Thread.__init__(self) self.name = name self.nloop = nloop self.nsec = nsec def run(self): print \"loop\", self.nloop, \"start at: \", ctime() sleep(self.nsec) print \"loop\", self.nloop, \"end at: \", ctime() print \"all start at: \",ctime() loops = [4,2] threads = [] nloops = range(len(loops)) for i in nloops: t = DaemonThreadDemo(i, loops[i], \"loop\") t.setDaemon(True) t.start() threads.append(t) for i in nloops: threads[i].join() print \"all end at: \",ctime() 生产者-消费者模式 然后我们再来介绍一种多线程模式，生产者-消费者模式，这也是现实生活中最常用的多线程模式。假设我们有这样一条工程，一共有两道工序。必须等到第一道工序结束了才能进行第二道工序。这时我们就引入了生产者和消费者的概念，第一道工序是生产者，第二道工序是消费者，分别是两个线程。 首先我们需要使用Queue队列模块，让多个线程之间共享数据。生产者不停的往队列里面加入货物，消费者不停的从队列里消费货物。假设我们一共有100个货物，生产者与消费者所需时间都是1秒以内的随机时间。 # coding=utf-8 import threading from Queue import Queue from random import random from time import ctime,sleep def writeQ(queue): for i in range(100): print \"Producting project for Q...\" sleep(random()) # sleep(random()/2.0) queue.put('xxx',1) print \"Size now\",queue.qsize() def readQ(queue): for i in range(100): print \"Consuming project from Q...\" sleep(random()) queue.get(1) print \"Size now\",queue.qsize() print \"all start at: \",ctime() funcs = [writeQ,readQ] nfunc = range(len(funcs)) q = Queue(48) threads = [] for i in nfunc: t = threading.Thread(target=funcs[i],args=(q,)) threads.append(t) for i in nfunc: threads[i].start() for i in nfunc: threads[i].join() print \"all end at: \",ctime() 保存为为threading_queue.py，运行，看一下结果。 八个线程 最后总花费大概50秒左右，已经能够把效率提高一倍了。可是仅仅这样怎么够，这才两个线程，让我们来开八个线程试一下，生产者和消费者各四个线程。 可以看到在把生产者消费者线程增多的时候，果然相比较效率提高了很多。 # coding=utf-8 import threading from Queue import Queue from random import random from time import ctime,sleep def writeQ(queue): for i in range(25): print \"Producting project for Q...\" sleep(random()) queue.put('xxx',1) print \"Size now\",queue.qsize() def readQ(queue): for i in range(25): print \"Consuming project from Q...\" sleep(random()) queue.get(1) print \"Size now\",queue.qsize() print \"all start at: \",ctime() funcs = [writeQ,readQ] nfunc = range(len(funcs)) q = Queue(48) threads = [] for i in nfunc: for j in range(4): t = threading.Thread(target=funcs[i],args=(q,)) threads.append(t) for i in range(8): threads[i].start() for i in range(8): threads[i].join() print \"all end at: \",ctime() 保存为threading_queue_last.py。 我们这是把生产者消费者同时执行，如果在生产者花费时间较短，只要时间在消费者的时候，我们可以先让生产者生产全部的货物，然后开多个子线程让消费者将其消费完为止。 资源锁定 前面我们已经看到因为线程同步的原因，输出的时候总是显得不那么整齐，就是因为多线程在抢占同一个资源的原因。而如果我们在对同一个数据进行操作时，因为多线程的原因，可能一个线程对其进行操作还未结束另一个线程就强行进行了下一轮更改，这样的话肯定会有一些问题。 所以这就需要资源锁定，当一个资源被锁定的时候，同时只能有一个资源对其进行操作，这样就保证了多线程的安全性。 我们先来看一下没有资源锁的情况 # coding=utf-8 import threading from time import ctime,sleep counter = 0 class MyThread1(threading.Thread): def __init__(self): threading.Thread.__init__(self) def run(self): global counter counter += 1 print \" \"+str(counter)+\" \" class MyThread2(threading.Thread): def __init__(self): threading.Thread.__init__(self) def run(self): global counter counter -= 1 print \" \"+str(counter)+\" \" if __name__ == '__main__': threads = [] for i in range(20): if i%2: t = MyThread1() else: t = MyThread2() threads.append(t) for t in threads: t.start() 保存为Threading_nolock.py，运行，看一下结果。 现在我们将其上锁。 # coding=utf-8 import threading from time import ctime,sleep counter = 0 lock = threading.Lock() class MyThread1(threading.Thread): def __init__(self): threading.Thread.__init__(self) def run(self): if lock.acquire(): global counter counter += 1 print \" \"+str(counter)+\" \" lock.release() class MyThread2(threading.Thread): def __init__(self): threading.Thread.__init__(self) def run(self): if lock.acquire(): global counter counter -= 1 print \" \"+str(counter)+\" \" lock.release() if __name__ == '__main__': threads = [] for i in range(20): if i%2: t = MyThread1() else: t = MyThread2() threads.append(t) for t in threads: t.start() 保存为threading_lock.py，运行，看一下结果。 使用线程锁的话需要手动的获取和释放，也可以采用简洁的方法,使用 上下文管理器。 def run(self): with lock: global counter counter -= 1 print \" \"+str(counter)+\" \" Lock 与 RLock 的区别，Lock 只能锁一次，再次请求就会挂起，RLock 自带计数器，在一个线程中可以请求多次，等计数器全部释放之后，其他线程才能取得资源。 本地变量 threadLocal 线程局部变量，又称线程上下文，避免了使用全局变量需加锁的困境和局部变量调用不清的麻烦。保证在每个线程中的变量都是在线程内可读可写的，而不会被其他线程污染。 # -*- coding: utf-8 -*- import threading local = threading.local() def process_name(): print \"hello %s, in %s\" % (local.name, threading.current_thread().name) def process_local(name): local.name = name process_name() if __name__ == '__main__': local.name = 'Cli' process_name() t1 = threading.Thread(target=process_local, args=('Bob', ), name='Target-A') # noqa t2 = threading.Thread(target=process_local, args=('Alice', ), name='Target-B') # noqa t1.start() t2.start() t1.join() t2.join() 线程变量是只能在当前线程中使用，在 flask 中即当前请求。但是 flask 不仅仅是只支持多线程，还有多进程，甚至单线程。 如何在单线程中使每个请求都获得一份局部变量。 将局部变量变成实例属性。 注意，线程上下文中的变量不仅不能在两个子线程之间传递，也不能在主线程和子线程之间传递 # -*- coding: utf-8 -*- import threading local = threading.local() def show_local(): print \"I'm child\" print \"local is %r\" % local print \"local value %s\" % hasattr(local, \"name\") if __name__ == '__main__': print \"I'm child\" print \"local is %r\" % local print \"local value %s\" % hasattr(local, \"name\") local.name = \"father\" print \"local value %s\" % local.name threading.Thread(target=show_local).start() print \"local value %s\" % local.name 线程数量 获得仍然存活的线程数量，其中包括主线程 # -*- coding: utf-8 -*- import os import time import random import threading def long_time_task(name): print 'Running task %s (%s)' % (name, os.getpid()) start = time.time() time.sleep(random.random() * 5) end = time.time() print 'Task %s run %0.2f econds.' % (name, end - start) if __name__ == '__main__': for i in xrange(10): threading.Thread(target=long_time_task, args=(str(i))).start() for i in xrange(10): print threading.enumerate(), len(threading.enumerate()) time.sleep(1) 线程池 线程池：基本思想还是一种对象池的思想，开辟一块内存空间，里面存放了众多(未死亡)的线程，池中线程执行调度由池管理器来处理。当有线程任务时，从池中取一个，执行完成后线程对象归池，这样可以避免反复创建线程对象所带来的性能开销，节省了系统的资源。 线程池的优点 避免线程的创建和销毁带来的性能开销。 避免大量的线程间因互相抢占系统资源导致的阻塞现象。 能够对线程进行简单的管理并提供定时执行、间隔执行等功能。 需要执行的线程数大于同时执行的线程。如果需要执行的线程数与同时执行的线程数相同，即线程池大小相同，线程池是不是就没有太大意义？ 所以线程池的应用场景就和队列的应用场景类似 如果执行的函数的参数由生产者提供，数量不定，即使用队列，将生产者也起一个线程，消费者多个线程 如果执行的函数的参数由主线程提供，数量固定，即使用线程池，将总参数和总线程数都放入线程池中，从线程池中取线程执行函数。 如果执行函数的结果需要传出，使用队列或者线程池不如使用消息队列的发布订阅模式 多个生产者的执行结果传入队列，单个消费者从队列中取出数据，但是如果消费者的速度大于生产者的速度，可能造成队列为空，消费者自行结束的情况 将函数放入线程池中执行，从线程池中取结果，对结果顺序要求不大的可以采用线程池 多个生产者的执行结果发布至消息队列，消费者从消息队列中监听数据。 线程池可以使用 Python 官方自带的 concurrent 库 多线程的结束 在多线程中,使用 Ctrl + C 一般不能结束子线程，因为发出的 kill signal 只能够被主线程 main 接收到，而不能够被子线程接收到，在 Mac 上可以使用 Ctrl + \\ 结束子线程，强行 quit 掉 这样也可以结束,但是感觉很奇怪 #!/usr/bin/env python # -*- coding: utf-8 -*- import sys, time, threading, abc from optparse import OptionParser def parse_options(): parser = OptionParser() parser.add_option(\"-t\", action=\"store\", type=\"int\", dest=\"threadNum\", default=1, help=\"thread count [1]\") (options, args) = parser.parse_args() return options class thread_sample(threading.Thread): def __init__(self, name): threading.Thread.__init__(self) self.name = name self.kill_received = False def run(self): while not self.kill_received: # your code print self.name, \"is active\" time.sleep(1) def has_live_threads(threads): return True in [t.isAlive() for t in threads] def main(): options = parse_options() threads = [] for i in range(options.threadNum): thread = thread_sample(\"thread#\" + str(i)) thread.start() threads.append(thread) while has_live_threads(threads): try: # synchronization timeout of threads kill [t.join(1) for t in threads if t is not None and t.isAlive()] except KeyboardInterrupt: # Ctrl-C handling and send kill to threads print \"Sending kill to threads...\" for t in threads: t.kill_received = True print \"Exited\" if __name__ == '__main__': main() 多线程的异常输出 多线程中虽然是与主线程共享变量，但是有自己的堆栈，而子线程异常信息是保存在堆栈上，主线程无法输出。 所以在某些多线程中子线程异常是无法察觉到的，没有报错信息，悄无声息的就死掉了。 需要借助一些子线程和主线程数据沟通的方式将子线程的异常输出，或者是使用日志记录。 线程定时器 多线程中自带一个异步的定时器，可以指定线程定时执行，甚至可以间隔执行。 默认定时器只执行一次，如果需要间隔执行，需要多次调用。 # -*- coding: utf-8 -*- import time import threading def on_timer(): print time.time() set_timer() def set_timer(): _timer = threading.Timer(10, on_timer) _timer.start() set_timer() while 1: time.sleep(5) print 'sleep', time.time() Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-10-08 02:52:24 "},"official/concurrent.html":{"url":"official/concurrent.html","title":"concurrent","keywords":"","body":"concurrent python 中的异步线程池库，集成 threading 和 multiprocessing 两个库。 可以使用 ThreadPoolExecutor 和 ProcessPoolExecutor 来选择线程池和进程池 # -*- coding: utf-8 -*- import time import requests import functools from concurrent import futures def time_count(func): @functools.wraps(func) def wrapper(*args, **kwargs): start = time.time() result = func(*args, **kwargs) end = time.time() print \"time\", end - start return result return wrapper urls = ['https://ele.me', 'https://baidu.com', 'https://jd.com', 'https://v2ex.com', 'https://windard.com', 'https://taobao.com', 'https://zhihu.com', 'https://vip.com', 'https://t.tt'] @time_count def main(): executor = futures.ThreadPoolExecutor() roads = [] results = [] for url in urls: future = executor.submit(requests.get, url) roads.append(future) for future in futures.as_completed(roads): result = future.result() results.append(result.status_code) executor.shutdown() return results @time_count def sync_main(): with futures.ThreadPoolExecutor() as executor: roads = executor.map(requests.get, urls) results = [result.status_code for result in roads] return results @time_count def async_main(): results = [] for url in urls: results.append(requests.get(url).status_code) return results if __name__ == '__main__': print main() print async_main() print sync_main() 参考链接 使用Python进行并发编程-PoolExecutor篇使用Python的 concurrent.futures 模块python并发库：concurrent.futures的使用python并发 1：使用 futures 处理并发 Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-10-08 02:52:24 "},"official/pdb.html":{"url":"official/pdb.html","title":"pdb","keywords":"","body":"pdb 打断点神器，再也不用依靠 pycharm 来打断点了。 标准用法 import pdb pdb.set_trace() 或者简化到一行 import pdb;pdb.set_trace() 然后再次运行，就会停在当前位置，可以查看当前位置的变量，环境和堆栈等相关信息。 还可以使用 python -m pdb file.py 使用 pdb 调试代码，默认停在第一行 pdb 中的命令 help [command] 显示相关语句帮助 n|next 下一步，不进入函数内部 j|jump [lineno] 跳转至某一行 c|continue 继续运行,没有断点则退出 pdb 调试 q|exit|quit 报错退出 l|list 列出上下文相关代码 w|where 显示堆栈信息 b|break [lineno] 打断点 cl|clear 清除所有断点 a|args 当前环境变量 r|return 退出当前函数 whatis [arg] 查看变量类型 s|step 下一步，进入函数内部 在 pdb 中可以设置变量，可以修改变量，可以侵入代码。 注意 a,b,c 都被占用了，不要再给 a,b,c 赋值了 Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-10-08 02:52:24 "},"third/":{"url":"third/","title":"第三方库","keywords":"","body":"第三方库 就是需要通过 pip 安装的库，非 python 自带的库。 但是需要 pip 安装的第三方库，有的也是第三方的官方库，&#x1F602;，比如 Redis 或者 MySQL 之类。也还是算 第三方库吧。 Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-24 10:10:53 "},"third/requests.html":{"url":"third/requests.html","title":"requests","keywords":"","body":"requests 吹爆 requests，HTTP client for human Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-23 04:45:19 "},"third/redis.html":{"url":"third/redis.html","title":"redis","keywords":"","body":"redis Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-10-08 03:00:34 "},"private/":{"url":"private/","title":"私人库","keywords":"","body":"私人库 Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-23 04:45:19 "},"other_tools.html":{"url":"other_tools.html","title":"其他","keywords":"","body":"其他 命令行工具 python自带了一个简单web的服务器，当前目录下启动,就可以在localhost:8080查看。 python -m SimpleHTTPServer 8080 python -m http.server for python 3 还有CGI服务器。 python -m CGIHTTPServer 8080 还有 FTP 服务器 python -m pyftpdlib 还有在线文档 python -m pydoc -p 8000 PHP 5.4版本及以上也自带了一个简单的web服务器，在当前目录下启动，就可以在localhost:8000查看。 php -S localhost:8000 真正最简单的 nodejs 服务器 npm install http-server -g http-server 启动在 8080 端口。 或者代码也很简单，实现 nodejs 的服务器。 var http = require('http'); http.createServer(function (req, res) { res.send('Hello'); res.end(); }).listen(3000); 保存为server.js,在当前目录下cmd里输入node server.js即可调用，在localhost:3000查看。 python 工具 不用进入 Python shell 执行 Python 语句,python -c \"import request\"。 python2 与 python3 共存的问题，我的解决方式是 Python2 就叫 python , pyhton3 则是 Python34 ,但是 pip 却不能这样做，python3 的 pip 可以这样使用 python34 -m pip install requests,然后就可以写一个 pip3.py 来这样。 其实你只需要把 python3 的 script 路径也导入 环境变量中就好了。。。其实应该用虚拟环境管理才是正解，没有虚拟环境就用 python -m pip install requests 指定python解释器 # coding=utf-8 import sys import subprocess print(\" \".join(sys.argv)) cmd = \"python34 -m pip \" + \" \".join(sys.argv[1:] + \" -i http://pypi.douban.com/simple --trusted-host pypi.douban.com\") obj = subprocess.Popen(cmd) obj.wait() 编码转义 urlencode 和 urldecode urllib.urlencode urlparse.parse_qsl | query_string.query_string urllib.quote urllib.unquote urlparse.urlparse urlparse.urlunparse 转义 re.escape 转义非法字符串 cgi.escape XSS 转义 # -*- coding: utf-8 -*- import urlparse import urllib from query_string import query_string data = { 'name': 'windard', 'year': 23, 'price': 100000000.111, 'company': 'https://ele.me' } if __name__ == '__main__': raw_data = urllib.urlencode(data) print raw_data parse_data = urlparse.parse_qsl(raw_data) print parse_data query_data = query_string(raw_data) print query_data 使用 python 内置的 json 显示 cat test.json | python -m json.tool echo '{\"name\": \"lucy\", \"age\": \"18\"}' | python -mjson.tool 还有一个很好的 bash 工具 jq $ echo '{\"name\": \"lucy\", \"age\": \"18\"}' |jq { \"name\": \"lucy\", \"age\": \"18\" } $ echo '{\"name\": \"lucy\", \"age\": \"18\"}' |jq '.name' \"lucy\" Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-23 04:45:19 "},"appendix.html":{"url":"appendix.html","title":"附录","keywords":"","body":"附录 Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-23 04:45:19 "},"Complainants.html":{"url":"Complainants.html","title":"碎碎念","keywords":"","body":"Gitbook 虽然我也和想用 Gitbook 官网，但是官网上也不能改主体，也不能改头像，&#x1F464;还要收费。太过分了，不行就用 GitHub Pages 没得选，用 Gitbook + GitHub Page 吧，算了，累了。Gitbook 官网默认的主题太丑了。 而且 Gitbook 还强行给我改文件结构，垃圾，&#x1F336;&#x1F414; 没人用就算了，不要放弃吖。 Plugins 受不了了，安装插件好慢吖。Gitbook 故意的么？已安装的插件还要再安装一遍。 可以通过 npm install gitbook-plugin-tbfed-pagefooter 的方式单独安装插件，使用 gitbook install 会安装全部插件 highlight 自带的插件，代码高亮 lunr 自带的插件，搜索引擎 search 自带的插件，导航栏查询，不能识别中文 sharing 自带的插件，右上角分享功能 font-settings 自带的插件，左上角的字体设置，\"A\" 键 livereload 自带的插件，文件改动自动加载 theme-default 自带的插件，默认主题，可以配置展示层次编号 { \"plugins\": [ \"theme-default\" ], \"pluginsConfig\": { \"theme-default\": { \"showLevel\": true } } } search-pro 高级搜索，支持中文 { \"plugins\": [ \"-lunr\", \"-search\", \"search-pro\" ] } search-plus 增强版的 search ，支持中文，感觉不出来和上面的区别&#x1F446;，但是上面那个似乎用的人更多 { \"plugins\": [\"-lunr\", \"-search\", \"search-plus\"] } ga Google 统计 如果报错 GitBook doesn't satisfy the requirements of this plugin: >=4.0.0-alpha.0.，试下使用 ga@1.0.1 { \"plugins\": [ \"ga\" ], \"pluginsConfig\": { \"ga\": { \"token\": \"UA-XXXX-Y\" } } } baidu 百度统计 { \"plugin\": [\"baidu\"], \"pluginsConfig\": { \"baidu\": { \"token\": \"YOUR TOKEN\" } } } sharing-plus 增强版的分享按钮，支持一些中国的社交网站，比如豆瓣，微信，微博等 { \"plugins\": [ \"-sharing\", \"sharing-plus\" ], \"pluginsConfig\": { \"sharing\": { \"douban\": false, \"facebook\": false, \"google\": true, \"pocket\": false, \"qq\": false, \"qzone\": true, \"twitter\": false, \"weibo\": true, \"all\": [ \"douban\", \"facebook\", \"google\", \"instapaper\", \"linkedin\", \"twitter\", \"weibo\", \"messenger\", \"qq\", \"qzone\", \"viber\", \"whatsapp\" ] } } } sitemap 生成 sitemap, 访问 /sitemap.xml 即可查看 { \"plugins\": [ \"sitemap\" ], \"sitemap\": { \"hostname\": \"https://python-book.windard.com/\" } } hide-element 可以隐藏不不想看到的元素 比如默认的 gitbook 左侧提示：Published with GitBook { \"plugins\": [ \"hide-element\" ], \"pluginsConfig\": { \"hide-element\": { \"elements\": [\".gitbook-link\"] } } } back-to-top-button 回到顶部 { \"plugins\": [ \"back-to-top-button\" ] } donate 赞赏&#x1F44D; { \"plugins\": [ \"back-to-top-button\" ], \"pluginsConfig\": { \"donate\": { \"wechat\": \"https://xxx.jpg\", \"alipay\": \"https://xxx.jpg\", \"title\": \"写的不错~ &#x1F44D;\", \"button\": \"打赏\", \"alipayText\": \"支付宝打赏\", \"wechatText\": \"微信打赏\" } } } github 展示一个 GitHub 头像在右上角 如果报错 GitBook doesn't satisfy the requirements of this plugin: >=4.0.0-alpha.0.，试下使用 github@2.0.0 { \"plugins\": [ \"github\" ], \"pluginsConfig\": { \"github\": { \"url\": \"https://github.com/your/repo\" } } } github-buttons 右上角展示 GitHub 标签, 可以指定 GitHub 仓库和标签类型，详见 GitHub:buttons { \"plugins\": [ \"github-buttons\" ], \"pluginsConfig\": { \"github-buttons\": { \"buttons\": [{ \"user\": \"windard\", \"repo\": \"python-book\", \"type\": \"star\", \"size\": \"small\" }, { \"user\": \"windard\", \"type\": \"follow\", \"width\": \"160\", \"count\": true, \"size\": \"small\" }] } } } disqus 使用 disqus 的评论体系,填入在 disqus 的站点名称即可。 如果报错 GitBook doesn't satisfy the requirements of this plugin: >=4.0.0-alpha.0.，试下使用 disqus@0.1.0 { \"plugins\": [\"disqus\"], \"pluginsConfig\": { \"disqus\": { \"shortName\": \"XXXXXXX\" } } } edit-link 在文章左上角展示一个 Edit on GitHub 的标签 { \"plugins\": [ \"edit-link\" ], \"pluginsConfig\": { \"edit-link\": { \"base\": \"https://github.com/itswl/gitbook/edit/master\", \"label\": \"Edit This Page\" } } } chapter-fold 默认导航栏是没有折贴的，一级标题和二级标题都默认展开，这个插件可以折叠导航栏 { \"plugins\": [\"chapter-fold\"] } expandable-chapters-small 上面 &#x1F446; 的导航栏折叠据说有问题，用这个插件组合使用可以修复，但是实际使用起来好像没啥问题。&#x1F602; { \"plugins\": [ \"expandable-chapters-small\" ] } expandable-chapters 和上面 &#x1F446; 的插件功能一样，点击箭头才能收缩，但是箭头比上面那个大 code 为代码模块增加复制按钮，为代码块增加行号 { \"plugins\" : [\"code\" ] } copy-code-button 同样的复制按钮，但是傻大黑粗不好看 { \"plugins\" : [ \"copy-code-button\" ] } splitter 左侧导航栏宽度动态可拖动 { \"plugins\": [ \"splitter\" ] } pageview-count 页面阅读量计数器 { \"plugins\": [\"pageview-count\"] } tbfed-pagefooter 展示页面最后更新时间 { \"plugins\": [ \"tbfed-pagefooter\" ], \"pluginsConfig\": { \"tbfed-pagefooter\": { \"copyright\": \"Copyright &copy 2020\", \"modify_label\": \"该文件最后修改时间：\", \"modify_format\": \"YYYY-MM-DD HH:mm:ss\" } } } image-captions 抓取图片的 alt 或者 title 字段并展示在图片下，但是展示效果并不太好 { \"plugins\": [\"image-captions\"] } anchors 对文章标题都生成锚点，展示效果类似于 GitHub { \"plugins\": [\"anchors\"] } popup 点击会在新标签页打开图片链接，其实这样并不太好，最好是在当前页面放大图片即可。 { \"plugins\": [ \"popup\" ] } lightbox 能够在页面上弹框展示图片，就是浮层出现的有点慢 { \"plugins\": [ \"popup\" ] } custom-favicon 更改页面 icon ，设置自定义 icon 会有 TypeError [ERR_INVALID_ARG_TYPE]: The \"path\" argument must be of type string. Received undefined 异常，无法修复 算了，就默认 icon 吧，也不是不能用 { \"plugins\" : [\"custom-favicon\"], \"pluginsConfig\" : { \"favicon\": \"path/to/favicon.ico\" } } 类似的还有 , 所以都有同样的问题 favicon-custom custom-favicon-new custom-favicon-fix custom-favicon-pro favicon 和上面&#x1F446;的类似，不过没有异常了，但是不能用，页面出现了两个 icon，最终显示的还是默认的 Gitbook icon { \"plugins\": [\"favicon\"], \"pluginsConfig\": { \"favicon\":{ \"shortcut\": \"assets/images/favicon.ico\", \"bookmark\": \"assets/images/favicon.ico\", \"appleTouch\": \"assets/images/apple-touch-icon.png\", \"appleTouchMore\": { \"120x120\": \"assets/images/apple-touch-icon-120x120.png\", \"180x180\": \"assets/images/apple-touch-icon-180x180.png\", } } } } toc 支持目录展示，在需要的地方插入目录 在这里我没有办法把上面&#x1F446;那行代码写出来贴这里，&#x1F602;，因为它会被识别成要插入目录 { \"plugins\": [ \"toc\" ] } atoc 使用和配置都与上面&#x1F446;的一致。但是在我这里使用时有问题，导致页面展示异常 { \"plugins\": [ \"atoc\" ] } page-toc 展示目录，通过另一种方式配置和展示，在文章头部配置，然后在文章右边就会出现目录，不会跟随滚动。 --- showToc: true --- { \"plugins\": [ \"page-toc\" ] } autocover 在生成电子书时，自动生成封面 但是已经无人维护，似乎问题很大。 { \"title\": \"Windard's Python Book\", \"description\": \"Python 学习的记录和总结\", \"author\": \"Windard\", \"plugins\": [\"autocover\"], \"pluginsConfig\": { \"autocover\": { \"font\": { \"size\": null, \"family\": \"Impact\", \"color\": \"#FFF\" }, \"size\": { \"w\": 1800, \"h\": 2360 }, \"background\": { \"color\": \"#09F\" } } } } 在生成电子书时，如果遇到 svg 图片转化的问题时，比如 error: error while generating page \"README.md\": Error: Error converting /tmp/tmp-281LPVxSm5Bv6U1/842cb21f.svg into /tmp/tmp-281LPVxSm5Bv6U1/302430b8.png 一般是 svgexport 的问题，可以试下安装低版本试下，其依赖的 puppeteer 高版本有问题。 npm i --unsafe-perm -g svgexport@0.3.2 版本问题 if (cb) cb.apply(this, arguments) ^ TypeError: cb.apply is not a function 一般是 node 版本的问题，比如 v12.18.4 或者 v14.12.0 , 使用 v12.18.1 或者 v13.14.0 版本就没问题。 Copyright © windard.com 2020 all right reserved，powered by Gitbook该文件最后修改时间： 2020-09-28 13:00:38 "}}